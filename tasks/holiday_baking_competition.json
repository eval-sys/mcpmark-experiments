{
  "task_id": "holiday_baking_competition",
  "task_name": "Holiday Baking Competition",
  "category_id": "shopping",
  "category_name": "Shopping",
  "description": "Research baking supplies for competition preparation including ingredient quality analysis, equipment comparisons, recipe optimization, and creating comprehensive shopping list with budget recommendations.",
  "author": "Yaoqi Ye",
  "created_at": "2025-08-17",
  "difficulty": "L3",
  "tags": [
    "search aggregation",
    "comparative analysis",
    "inventory management"
  ],
  "mcp": [
    "playwright"
  ],
  "meta_data": {
    "stateType": "video",
    "stateContent": null,
    "stateUrl": "https://storage.mcpmark.ai/tasks_state/playwright_video/one-stop-market.mp4",
    "stateOriginalUrl": "https://github.com/web-arena-x/webarena/tree/main/environment_docker"
  },
  "instruction": "\n\n**Task Requirements:**\n\n1. Search 'gingerbread', sort by price (high to low):\n   - Add most expensive product to comparison list\n   - Record SKU of second most expensive product\n\n2. Search 'cookie' with price range $20.00-$40.00:\n   - Find product with highest rating % and at least 5 reviews in the first 2 pages (if tied, choose lowest price)\n   - Record SKU and rating %\n   - Select \"Cookies: Oatmeal Chocolate Chunk\" flavor if required\n   - Add to cart with quantity 2\n\n3. Search 'chocolate', sort by price (low to high):\n   - Find cheapest product with at least 1 review\n   - Record price and review count\n   - Select \"Peanut Butter Flavor\" if required\n   - Add to cart with quantity 3\n\n4. In cart:\n   - Update cookie quantity from 2 to 5\n   - Record cart subtotal and total items count\n\n5. Search 'gingerbread', go to page 2:\n   - Find third product on page 2\n   - Record SKU, price, and manufacturer\n\n**Output Format:**\n\n```\n<answer>\nSecondGingerbreadSKU|sku\nHighestRatedCookieSKURating|sku:rating%\nCheapestChocolatePriceReviews|$price:reviews\nCartSubtotalAfterUpdate|$amount\nTotalCartItems|count\nPage2ThirdProductSKUPrice|sku:$price\nProductManufacturer|manufacturer\n</answer>\n```\n\n",
  "verify": "import asyncio\nimport sys\nimport re\nimport os\nimport json\nfrom pathlib import Path\n\n\ndef get_model_response():\n    \"\"\"\n    Get the model's response from the MCP_MESSAGES environment variable.\n    Returns the last assistant message text.\n    \"\"\"\n    messages_path = os.getenv(\"MCP_MESSAGES\")\n    print(f\"MCP_MESSAGES: {messages_path}\")\n    if not messages_path:\n        print(\"Warning: MCP_MESSAGES environment variable not set\", file=sys.stderr)\n        return None\n\n    try:\n        with open(messages_path, \"r\") as f:\n            messages = json.load(f)\n\n        # Find the last assistant message\n        for message in reversed(messages):\n            if (\n                message.get(\"role\") == \"assistant\"\n                and message.get(\"status\") == \"completed\"\n                and message.get(\"type\") == \"message\"\n            ):\n                content = message.get(\"content\", [])\n                for item in content:\n                    if item.get(\"type\") == \"output_text\":\n                        return item.get(\"text\", \"\")\n\n        print(\"Warning: No assistant response found in messages\", file=sys.stderr)\n        return None\n    except Exception as e:\n        print(f\"Error reading messages file: {str(e)}\", file=sys.stderr)\n        return None\n\n\ndef parse_answer_format(text):\n    \"\"\"\n    Parse the <answer>...</answer> format from the agent's output.\n    Returns a dictionary with the parsed values.\n    \"\"\"\n    if not text:\n        return None\n\n    # Look for <answer>...</answer> pattern\n    match = re.search(r\"<answer>(.*?)</answer>\", text, re.IGNORECASE | re.DOTALL)\n    if not match:\n        return None\n\n    answer_content = match.group(1).strip()\n\n    # Parse each line\n    result = {}\n    lines = answer_content.split(\"\\n\")\n\n    if len(lines) != 7:\n        print(f\"Error: Expected 7 lines in answer, got {len(lines)}\", file=sys.stderr)\n        return None\n\n    for line in lines:\n        if \"|\" in line:\n            key, value = line.split(\"|\", 1)\n            result[key.strip()] = value.strip()\n\n    return result\n\n\ndef load_expected_answer(label_path):\n    \"\"\"\n    Load the expected answer from label.txt file.\n    Returns a dictionary with the expected values.\n    \"\"\"\n    try:\n        with open(label_path, \"r\") as f:\n            lines = f.read().strip().split(\"\\n\")\n\n        expected = {}\n        for line in lines:\n            if \"|\" in line:\n                key, value = line.split(\"|\", 1)\n                expected[key.strip()] = value.strip()\n\n        return expected\n    except Exception as e:\n        print(f\"Error reading label file: {str(e)}\", file=sys.stderr)\n        return None\n\n\ndef compare_answers(model_answer, expected_answer):\n    \"\"\"\n    Compare the model's answer with the expected answer.\n    Returns True if all key information matches, False otherwise.\n    \"\"\"\n    if not model_answer or not expected_answer:\n        return False\n\n    # Check each expected key\n    mismatches = []\n    for key, expected_value in expected_answer.items():\n        model_value = model_answer.get(key, \"\")\n\n        # Special handling for different types of values\n        if key == \"SecondGingerbreadSKU\":\n            # SKU should match exactly (case-insensitive)\n            if model_value.upper() != expected_value.upper():\n                mismatches.append(\n                    f\"{key}: expected '{expected_value}', got '{model_value}'\"\n                )\n                \n        elif key in [\"CartSubtotalAfterUpdate\"]:\n            # For price fields, only support $XX.XX format\n            # Check if model value has correct format\n            if not model_value.startswith(\"$\"):\n                mismatches.append(\n                    f\"{key}: incorrect format - expected '$XX.XX' format, got '{model_value}'\"\n                )\n            else:\n                # Normalize and compare values\n                expected_clean = expected_value.replace(\"$\", \"\").replace(\",\", \"\")\n                model_clean = model_value.replace(\"$\", \"\").replace(\",\", \"\")\n                # Allow some tolerance for price calculations (within $0.01)\n                try:\n                    expected_float = float(expected_clean)\n                    model_float = float(model_clean)\n                    if abs(expected_float - model_float) > 0.01:\n                        mismatches.append(\n                            f\"{key}: expected '{expected_value}', got '{model_value}'\"\n                        )\n                except ValueError:\n                    if expected_value != model_value:\n                        mismatches.append(\n                            f\"{key}: expected '{expected_value}', got '{model_value}'\"\n                        )\n                    \n        elif key in [\"TotalCartItems\"]:\n            # Should be a number\n            if model_value != expected_value:\n                mismatches.append(\n                    f\"{key}: expected '{expected_value}', got '{model_value}'\"\n                )\n                \n        elif key in [\"HighestRatedCookieSKURating\", \"CheapestChocolatePriceReviews\", \"Page2ThirdProductSKUPrice\"]:\n            # Colon-separated fields (sku:rating, price:reviews, sku:price)\n            if \":\" in expected_value and \":\" in model_value:\n                expected_parts = expected_value.split(\":\", 1)\n                model_parts = model_value.split(\":\", 1)\n                if len(expected_parts) == 2 and len(model_parts) == 2:\n                    # For price fields, normalize the price part\n                    if key == \"CheapestChocolatePriceReviews\":\n                        # Check if price part has correct format ($XX.XX)\n                        if not model_parts[0].startswith(\"$\"):\n                            mismatches.append(\n                                f\"{key}: incorrect format - price part should start with '$', got '{model_value}'\"\n                            )\n                        else:\n                            expected_price = expected_parts[0].replace(\"$\", \"\").replace(\",\", \"\")\n                            model_price = model_parts[0].replace(\"$\", \"\").replace(\",\", \"\")\n                            try:\n                                if abs(float(expected_price) - float(model_price)) > 0.01 or expected_parts[1] != model_parts[1]:\n                                    mismatches.append(\n                                        f\"{key}: expected '{expected_value}', got '{model_value}'\"\n                                    )\n                            except ValueError:\n                                if expected_value != model_value:\n                                    mismatches.append(\n                                        f\"{key}: expected '{expected_value}', got '{model_value}'\"\n                                    )\n                    elif key == \"Page2ThirdProductSKUPrice\":\n                        # Check if price part has correct format ($XX.XX)\n                        if not model_parts[1].startswith(\"$\"):\n                            mismatches.append(\n                                f\"{key}: incorrect format - price part should start with '$', got '{model_value}'\"\n                            )\n                        else:\n                            expected_price = expected_parts[1].replace(\"$\", \"\").replace(\",\", \"\")\n                            model_price = model_parts[1].replace(\"$\", \"\").replace(\",\", \"\")\n                            try:\n                                if expected_parts[0] != model_parts[0] or abs(float(expected_price) - float(model_price)) > 0.01:\n                                    mismatches.append(\n                                        f\"{key}: expected '{expected_value}', got '{model_value}'\"\n                                    )\n                            except ValueError:\n                                if expected_value != model_value:\n                                    mismatches.append(\n                                        f\"{key}: expected '{expected_value}', got '{model_value}'\"\n                                    )\n                    else:\n                        # For rating fields, exact match\n                        if expected_value != model_value:\n                            mismatches.append(\n                                f\"{key}: expected '{expected_value}', got '{model_value}'\"\n                            )\n                else:\n                    mismatches.append(\n                        f\"{key}: expected '{expected_value}', got '{model_value}'\"\n                    )\n            else:\n                if expected_value != model_value:\n                    mismatches.append(\n                        f\"{key}: expected '{expected_value}', got '{model_value}'\"\n                    )\n        else:\n            # Exact match for other fields (like ProductManufacturer)\n            if model_value != expected_value:\n                mismatches.append(\n                    f\"{key}: expected '{expected_value}', got '{model_value}'\"\n                )\n\n    if mismatches:\n        print(\"\\n=== Answer Comparison Mismatches ===\", file=sys.stderr)\n        for mismatch in mismatches:\n            print(f\"✗ {mismatch}\", file=sys.stderr)\n        return False\n\n    print(\"\\n=== Answer Comparison ===\", file=sys.stderr)\n    print(\"✓ All key information matches the expected answer\", file=sys.stderr)\n    return True\n\n\nasync def verify() -> bool:\n    \"\"\"\n    Verifies that the holiday baking competition task has been completed correctly.\n    Checks the model's answer against the expected label.\n    \"\"\"\n    # Get the label file path\n    label_path = Path(__file__).parent / \"label.txt\"\n\n    # Load expected answer\n    expected_answer = load_expected_answer(label_path)\n    if not expected_answer:\n        print(\"Error: Could not load expected answer from label.txt\", file=sys.stderr)\n        return False\n\n    # Get model's response from MCP_MESSAGES\n    model_response = get_model_response()\n    if model_response:\n        print(\"Found model response, parsing answer format...\", file=sys.stderr)\n        model_answer = parse_answer_format(model_response)\n\n        if model_answer:\n            print(\"\\n=== Model Answer Parsed ===\", file=sys.stderr)\n            for key, value in model_answer.items():\n                print(f\"{key}: {value}\", file=sys.stderr)\n\n            # Compare answers\n            answer_match = compare_answers(model_answer, expected_answer)\n            if not answer_match:\n                print(\"\\nModel answer does not match expected answer\", file=sys.stderr)\n                return False\n            print(\"\\n✓ Model answer matches expected answer\", file=sys.stderr)\n            return True\n        else:\n            print(\n                \"Warning: Could not parse answer format from model response\",\n                file=sys.stderr,\n            )\n            return False\n    else:\n        print(\"No model response found\", file=sys.stderr)\n        return False\n\n\ndef main():\n    \"\"\"\n    Executes the verification process and exits with a status code.\n    \"\"\"\n    result = asyncio.run(verify())\n    sys.exit(0 if result else 1)\n\n\nif __name__ == \"__main__\":\n    main()"
}