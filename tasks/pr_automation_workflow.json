{
  "task_id": "pr_automation_workflow",
  "task_name": "Pr Automation Workflow",
  "category_id": "mcpmark-cicd",
  "category_name": "MCPMark CI/CD",
  "description": "Create comprehensive PR automation with parallel jobs for code quality, testing, security scanning, and build validation.",
  "author": "Zijian Wu",
  "created_at": "2025-08-15",
  "difficulty": "L3",
  "tags": [
    "pr workflows",
    "ci/cd automation",
    "workflow automation"
  ],
  "mcp": [
    "github"
  ],
  "meta_data": {
    "stateType": "url",
    "stateContent": null,
    "stateUrl": "https://github.com/mcpmark-source/mcpmark-cicd",
    "stateOriginalUrl": null
  },
  "instruction": "I need you to create a comprehensive Pull Request automation workflow for this Node.js project. The project currently has no GitHub Actions workflows, so you'll be building a PR-focused CI/CD workflow from scratch that responds to pull request events. Here's what needs to be implemented:\n\n## Pull Request Automation Workflow\n\nCreate `.github/workflows/pr-automation.yml` that triggers on `pull_request` events (opened, synchronize, reopened) with these jobs:\n\n### 1. **code-quality** job (name: `code-quality`):\n  - Runs ESLint checks using `npm run lint`\n  - Runs Prettier formatting checks\n  - Posts code quality results as PR comment (must include keywords: \"Code Quality Report\", \"ESLint\", \"Prettier\")\n\n### 2. **testing-suite** job (name: `testing-suite`):\n  - Runs full test suite with `npm test`\n  - Generates test coverage report\n  - Posts coverage summary as PR comment (must include keywords: \"Test Coverage Report\")\n  - Uploads coverage artifacts\n\n### 3. **security-scan** job (name: `security-scan`):\n  - Runs dependency vulnerability checks\n  - Scans for secrets in code changes\n  - Creates security report as PR comment (must include keywords: \"Security Scan Report\", \"Vulnerabilities\", \"Dependencies\")\n\n### 4. **build-validation** job (name: `build-validation`):\n  - Attempts to build the application\n  - Validates all endpoints are accessible\n  - Creates deployment preview artifacts\n  - Posts build status as PR comment (must include keywords: \"Build Validation\")\n\n**IMPORTANT: All four jobs must run in parallel.**\n\n## Implementation Requirements:\n\n**Step 1: Create Feature Branch**\nCreate a new branch called `pr-automation-workflow` from main.\n\n**Step 2: Create the Workflow**\nCreate `.github/workflows/pr-automation.yml` with proper YAML syntax:\n- Appropriate triggers for pull_request events\n- All four jobs configured to run in parallel\n- Avoid identifier conflicts in github-script actions\n\n**Step 3: Create and Merge Pull Request**\nCreate a comprehensive pull request and merge it to main:\n- Title: \"Implement Pull Request Automation Workflow\"\n- Detailed description of the workflow and its purpose\n- Merge the pull request to main branch\n\n## Important Notes:\n\n- **All jobs MUST run in parallel**\n- Ensure your PR satisfies ALL required checks\n- The workflow should handle edge cases, have proper error recovery, and provide clear logging",
  "verify": "import sys\nimport os\nimport requests\nimport time\nfrom typing import Dict, List, Optional, Tuple\nfrom dotenv import load_dotenv\nimport base64\n\n\ndef _get_github_api(\n    endpoint: str, headers: Dict[str, str], owner: str, repo: str\n) -> Tuple[bool, Optional[Dict]]:\n    \"\"\"Make a GET request to GitHub API and return (success, response).\"\"\"\n    url = f\"https://api.github.com/repos/{owner}/{repo}/{endpoint}\"\n    try:\n        response = requests.get(url, headers=headers)\n        if response.status_code == 200:\n            return True, response.json()\n        elif response.status_code == 404:\n            return False, None\n        else:\n            print(f\"API error for {endpoint}: {response.status_code}\", file=sys.stderr)\n            return False, None\n    except Exception as e:\n        print(f\"Exception for {endpoint}: {e}\", file=sys.stderr)\n        return False, None\n\n\ndef _post_github_api(\n    endpoint: str, headers: Dict[str, str], owner: str, repo: str, data: Dict\n) -> Tuple[bool, Optional[Dict]]:\n    \"\"\"Make a POST request to GitHub API and return (success, response).\"\"\"\n    url = f\"https://api.github.com/repos/{owner}/{repo}/{endpoint}\"\n    try:\n        response = requests.post(url, headers=headers, json=data)\n        if response.status_code in [200, 201]:\n            return True, response.json()\n        else:\n            print(\n                f\"API error for {endpoint}: {response.status_code} - {response.text}\",\n                file=sys.stderr,\n            )\n            return False, None\n    except Exception as e:\n        print(f\"Exception for {endpoint}: {e}\", file=sys.stderr)\n        return False, None\n\n\ndef _patch_github_api(\n    endpoint: str, headers: Dict[str, str], owner: str, repo: str, data: Dict\n) -> Tuple[bool, Optional[Dict]]:\n    \"\"\"Make a PATCH request to GitHub API and return (success, response).\"\"\"\n    url = f\"https://api.github.com/repos/{owner}/{repo}/{endpoint}\"\n    try:\n        response = requests.patch(url, headers=headers, json=data)\n        if response.status_code == 200:\n            return True, response.json()\n        else:\n            print(\n                f\"API error for {endpoint}: {response.status_code} - {response.text}\",\n                file=sys.stderr,\n            )\n            return False, None\n    except Exception as e:\n        print(f\"Exception for {endpoint}: {e}\", file=sys.stderr)\n        return False, None\n\n\ndef _get_file_content(\n    file_path: str,\n    headers: Dict[str, str],\n    owner: str,\n    repo: str,\n    ref: str = \"main\",\n) -> Optional[str]:\n    \"\"\"Get the content of a file from the repository.\"\"\"\n    success, result = _get_github_api(\n        f\"contents/{file_path}?ref={ref}\", headers, owner, repo\n    )\n    if not success or not result:\n        return None\n\n    try:\n        content = base64.b64decode(result.get(\"content\", \"\")).decode(\"utf-8\")\n        return content\n    except Exception as e:\n        print(f\"Content decode error for {file_path}: {e}\", file=sys.stderr)\n        return None\n\n\ndef _find_pr_by_title(\n    title: str, headers: Dict[str, str], owner: str, repo: str\n) -> Optional[Dict]:\n    \"\"\"Find a PR by exact title match.\"\"\"\n    for state in [\"closed\", \"open\"]:\n        success, prs = _get_github_api(\n            f\"pulls?state={state}&per_page=100\", headers, owner, repo\n        )\n        if success and prs:\n            for pr in prs:\n                if pr.get(\"title\") == title:\n                    return pr\n    return None\n\n\ndef _wait_for_workflow_completion(\n    headers: Dict[str, str],\n    owner: str,\n    repo: str,\n    workflow_file: str,\n    max_wait: int = 600,\n) -> bool:\n    \"\"\"Wait for GitHub Actions workflows to complete processing.\"\"\"\n    print(f\"‚è≥ Waiting for {workflow_file} workflows to complete...\")\n\n    start_time = time.time()\n    no_workflow_check_count = 0\n\n    while time.time() - start_time < max_wait:\n        try:\n            success, response = _get_github_api(\n                f\"actions/workflows/{workflow_file}/runs?per_page=10\",\n                headers,\n                owner,\n                repo,\n            )\n\n            if success and response:\n                runs = response.get(\"workflow_runs\", [])\n                if len(runs) > 0:\n                    running_count = 0\n                    completed_count = 0\n\n                    for run in runs[:5]:  # Check recent runs\n                        status = run[\"status\"]\n                        if status == \"completed\":\n                            completed_count += 1\n                        elif status in [\"in_progress\", \"queued\"]:\n                            running_count += 1\n\n                    print(\n                        f\"   Status: {completed_count} completed, {running_count} running/queued\"\n                    )\n\n                    if running_count == 0:\n                        print(f\"‚úÖ All {workflow_file} workflows completed.\")\n                        return True\n                else:\n                    # No workflow runs found\n                    no_workflow_check_count += 1\n                    if no_workflow_check_count == 1:\n                        print(\n                            \"   No workflow runs found yet, waiting 5 seconds and checking once more...\"\n                        )\n                        time.sleep(5)\n                        continue\n                    elif no_workflow_check_count >= 2:\n                        print(\n                            f\"‚ö†Ô∏è No workflow runs detected after 2 checks. {workflow_file} may not have been triggered.\"\n                        )\n                        print(\"   Continuing with verification...\")\n                        return False\n\n            print(f\"‚è≥ Still waiting... ({int(time.time() - start_time)}s elapsed)\")\n            time.sleep(10)\n\n        except Exception as e:\n            print(f\"‚ö†Ô∏è Error checking workflow status: {e}\")\n            time.sleep(10)\n\n    print(f\"‚ö†Ô∏è Workflow completion wait timed out after {max_wait}s\")\n    return False\n\n\ndef _verify_workflow_file(\n    headers: Dict[str, str], owner: str, repo: str\n) -> Tuple[bool, List[str]]:\n    \"\"\"Verify that the workflow file exists and has correct content.\"\"\"\n    print(\"\\nüìÑ Verifying workflow file...\")\n    errors = []\n\n    workflow_content = _get_file_content(\n        \".github/workflows/pr-automation.yml\", headers, owner, repo\n    )\n\n    if not workflow_content:\n        return False, [\n            \"Workflow file .github/workflows/pr-automation.yml not found in main branch\"\n        ]\n\n    print(\"   ‚úÖ Workflow file exists in main branch\")\n\n    # Verify required components\n    required_events = [\"opened\", \"synchronize\", \"reopened\"]\n    required_jobs = [\n        \"code-quality\",\n        \"testing-suite\",\n        \"security-scan\",\n        \"build-validation\",\n    ]\n\n    if \"pull_request:\" not in workflow_content:\n        errors.append(\"Workflow missing pull_request trigger\")\n    else:\n        print(\"   ‚úÖ Pull request trigger found\")\n\n    for event in required_events:\n        if event not in workflow_content:\n            errors.append(f\"Missing event trigger: {event}\")\n\n    if not errors:\n        print(f\"   ‚úÖ Required events found: {required_events}\")\n\n    for job in required_jobs:\n        if f\"{job}:\" not in workflow_content:\n            errors.append(f\"Missing job: {job}\")\n\n    if not errors:\n        print(f\"   ‚úÖ All 4 required jobs found: {required_jobs}\")\n\n    return len(errors) == 0, errors\n\n\ndef _verify_main_pr_merged(\n    headers: Dict[str, str], owner: str, repo: str\n) -> Tuple[bool, List[str], Optional[Dict]]:\n    \"\"\"Verify that the main PR implementing the workflow was merged.\"\"\"\n    print(\"\\nüîç Verifying main PR was merged...\")\n    errors = []\n\n    pr = _find_pr_by_title(\n        \"Implement Pull Request Automation Workflow\", headers, owner, repo\n    )\n\n    if not pr:\n        return (\n            False,\n            [\"Main PR 'Implement Pull Request Automation Workflow' not found\"],\n            None,\n        )\n\n    pr_number = pr[\"number\"]\n    print(f\"   Found PR #{pr_number}\")\n\n    if not pr.get(\"merged_at\", False):\n        errors.append(f\"PR #{pr_number} was not merged\")\n    else:\n        print(f\"   ‚úÖ PR #{pr_number} was merged\")\n\n    if pr.get(\"head\", {}).get(\"ref\") != \"pr-automation-workflow\":\n        errors.append(f\"PR #{pr_number} was not from pr-automation-workflow branch\")\n    else:\n        print(\"   ‚úÖ PR was from pr-automation-workflow branch\")\n\n    if pr.get(\"base\", {}).get(\"ref\") != \"main\":\n        errors.append(f\"PR #{pr_number} was not merged to main branch\")\n    else:\n        print(\"   ‚úÖ PR was merged to main branch\")\n\n    return len(errors) == 0, errors, pr\n\n\ndef _verify_workflow_runs(\n    pr_data: Dict, headers: Dict[str, str], owner: str, repo: str\n) -> Tuple[bool, List[str]]:\n    \"\"\"Verify that workflow runs occurred for the PR and all 4 jobs ran in parallel.\"\"\"\n    print(\"\\n‚öôÔ∏è Verifying workflow runs...\")\n    errors = []\n\n    pr_number = pr_data[\"number\"]\n\n    # Get workflow runs for the PR\n    success, runs_response = _get_github_api(\n        \"actions/runs?event=pull_request&per_page=50\", headers, owner, repo\n    )\n\n    if not success:\n        return False, [\"Failed to fetch workflow runs\"]\n\n    pr_runs = []\n    pr_head_sha = pr_data.get(\"head\", {}).get(\"sha\")\n\n    for run in runs_response.get(\"workflow_runs\", []):\n        # Method 1: Check if this run is associated with the PR's head SHA\n        if pr_head_sha and run.get(\"head_sha\") == pr_head_sha:\n            pr_runs.append(run)\n            continue\n\n        # Method 2: Check pull_requests field (may be empty for merged PRs)\n        for pr in run.get(\"pull_requests\", []):\n            if pr.get(\"number\") == pr_number:\n                pr_runs.append(run)\n                break\n\n    if not pr_runs:\n        # Try alternative approach: get runs by head branch\n        pr_head_ref = pr_data.get(\"head\", {}).get(\"ref\")\n        if pr_head_ref:\n            success, branch_runs = _get_github_api(\n                f\"actions/runs?branch={pr_head_ref}&per_page=50\", headers, owner, repo\n            )\n            if success:\n                pr_runs = branch_runs.get(\"workflow_runs\", [])\n\n    if not pr_runs:\n        return False, [\n            f\"No workflow runs found for PR #{pr_number} (head_sha: {pr_head_sha})\"\n        ]\n\n    print(f\"   Found {len(pr_runs)} workflow run(s) for PR #{pr_number}\")\n\n    # Check the most recent run\n    latest_run = pr_runs[0]  # GitHub returns runs in descending order by creation time\n    run_id = latest_run[\"id\"]\n\n    if latest_run[\"conclusion\"] != \"success\":\n        errors.append(\n            f\"Latest workflow run {run_id} did not succeed (conclusion: {latest_run['conclusion']})\"\n        )\n    else:\n        print(f\"   ‚úÖ Latest workflow run {run_id} succeeded\")\n\n    # Get jobs for this run\n    success, jobs_response = _get_github_api(\n        f\"actions/runs/{run_id}/jobs\", headers, owner, repo\n    )\n\n    if not success:\n        return False, [\"Failed to fetch workflow jobs\"]\n\n    jobs = jobs_response.get(\"jobs\", [])\n    expected_jobs = [\n        \"code-quality\",\n        \"testing-suite\",\n        \"security-scan\",\n        \"build-validation\",\n    ]\n\n    found_jobs = [job[\"name\"] for job in jobs]\n    missing_jobs = [job for job in expected_jobs if job not in found_jobs]\n\n    if missing_jobs:\n        errors.append(f\"Missing jobs: {missing_jobs}. Found: {found_jobs}\")\n    else:\n        print(f\"   ‚úÖ All 4 required jobs found: {found_jobs}\")\n\n    # Verify all jobs succeeded\n    failed_jobs = [job[\"name\"] for job in jobs if job[\"conclusion\"] != \"success\"]\n    if failed_jobs:\n        errors.append(f\"Failed jobs: {failed_jobs}\")\n    else:\n        print(\"   ‚úÖ All jobs completed successfully\")\n\n    # Verify jobs ran in parallel (started around the same time)\n    if len(jobs) >= 4:\n        start_times = [job[\"started_at\"] for job in jobs if job[\"started_at\"]]\n        if len(start_times) >= 4:\n            # Check if all jobs started within 2 minutes of each other\n            import datetime\n\n            start_dt = [\n                datetime.datetime.fromisoformat(t.replace(\"Z\", \"+00:00\"))\n                for t in start_times\n            ]\n            time_diff = max(start_dt) - min(start_dt)\n            if time_diff.total_seconds() > 120:  # 2 minutes\n                errors.append(\n                    f\"Jobs did not run in parallel (time span: {time_diff.total_seconds()}s)\"\n                )\n            else:\n                print(\"   ‚úÖ Jobs ran in parallel\")\n        else:\n            errors.append(\"Not enough job start times to verify parallel execution\")\n\n    return len(errors) == 0, errors\n\n\ndef _verify_pr_comments(\n    pr_data: Dict, headers: Dict[str, str], owner: str, repo: str\n) -> Tuple[bool, List[str]]:\n    \"\"\"Verify that PR has required automation comments from GitHub Actions bot.\"\"\"\n    print(\"\\nüí¨ Verifying PR comments...\")\n    errors = []\n\n    pr_number = pr_data[\"number\"]\n\n    success, comments = _get_github_api(\n        f\"issues/{pr_number}/comments\", headers, owner, repo\n    )\n\n    if not success:\n        return False, [\"Failed to fetch PR comments\"]\n\n    # Filter for GitHub Actions bot comments only\n    bot_comments = [\n        comment\n        for comment in comments\n        if comment.get(\"user\", {}).get(\"login\") == \"github-actions[bot]\"\n    ]\n\n    if not bot_comments:\n        return False, [\"No comments found from GitHub Actions bot\"]\n\n    print(f\"   Found {len(bot_comments)} comment(s) from GitHub Actions bot\")\n\n    # Get all bot comment bodies\n    bot_comment_bodies = [comment.get(\"body\", \"\") for comment in bot_comments]\n\n    # Define required automation reports with their keywords\n    required_reports = [\n        {\n            \"name\": \"Code Quality Report\",\n            \"main_keywords\": [\"Code Quality Report\"],\n            \"sub_keywords\": [\"ESLint\", \"Prettier\"],\n            \"found\": False,\n        },\n        {\n            \"name\": \"Test Coverage Report\",\n            \"main_keywords\": [\"Test Coverage Report\"],\n            \"sub_keywords\": [],\n            \"found\": False,\n        },\n        {\n            \"name\": \"Security Scan Report\",\n            \"main_keywords\": [\"Security Scan Report\"],\n            \"sub_keywords\": [\"Vulnerabilities\", \"Dependencies\"],\n            \"found\": False,\n        },\n        {\n            \"name\": \"Build Validation Report\",\n            \"main_keywords\": [\"Build Validation\"],\n            \"sub_keywords\": [],\n            \"found\": False,\n        },\n    ]\n\n    # Check each bot comment for the required reports\n    for comment_body in bot_comment_bodies:\n        for report in required_reports:\n            # Check if this comment contains any of the main keywords for this report\n            if any(keyword in comment_body for keyword in report[\"main_keywords\"]):\n                if not report[\"found\"]:  # Only mark as found once\n                    report[\"found\"] = True\n                    print(f\"   ‚úÖ Found {report['name']}\")\n\n                    # Verify sub-keywords are present in this specific comment\n                    for sub_keyword in report[\"sub_keywords\"]:\n                        if sub_keyword not in comment_body:\n                            errors.append(\n                                f\"Missing sub-keyword '{sub_keyword}' in {report['name']}\"\n                            )\n                        else:\n                            print(\n                                f\"   ‚úÖ Found sub-keyword '{sub_keyword}' in {report['name']}\"\n                            )\n\n    # Check if all required reports were found\n    for report in required_reports:\n        if not report[\"found\"]:\n            errors.append(f\"Missing {report['name']} from GitHub Actions bot\")\n\n    # Verify we have exactly 4 automation reports\n    found_reports = sum(1 for report in required_reports if report[\"found\"])\n    if found_reports != 4:\n        errors.append(f\"Expected 4 automation reports, but found {found_reports}\")\n    else:\n        print(\"   ‚úÖ All 4 required automation reports found from GitHub Actions bot\")\n\n    return len(errors) == 0, errors\n\n\ndef _create_test_pr(\n    title: str,\n    branch: str,\n    content: str,\n    file_path: str,\n    headers: Dict[str, str],\n    owner: str,\n    repo: str,\n) -> Optional[int]:\n    \"\"\"Create a test PR with specific content designed to fail a check.\"\"\"\n    print(f\"   Creating test PR: {title}\")\n\n    # Create branch\n    success, main_ref = _get_github_api(\"git/ref/heads/main\", headers, owner, repo)\n    if not success:\n        print(\"   ‚ùå Failed to get main branch reference\")\n        return None\n\n    main_sha = main_ref[\"object\"][\"sha\"]\n\n    branch_data = {\"ref\": f\"refs/heads/{branch}\", \"sha\": main_sha}\n\n    success, _ = _post_github_api(\"git/refs\", headers, owner, repo, branch_data)\n    if not success:\n        # Branch might already exist, try to delete and recreate\n        print(f\"   Branch {branch} already exists, trying to delete and recreate...\")\n        import requests\n\n        # Force delete existing branch\n        delete_url = (\n            f\"https://api.github.com/repos/{owner}/{repo}/git/refs/heads/{branch}\"\n        )\n        delete_response = requests.delete(delete_url, headers=headers)\n\n        if delete_response.status_code == 204:\n            print(f\"   Successfully deleted existing branch {branch}\")\n            # Wait a moment for deletion to complete\n            import time\n\n            time.sleep(2)\n\n            # Try creating again\n            success, _ = _post_github_api(\"git/refs\", headers, owner, repo, branch_data)\n            if not success:\n                print(f\"   ‚ùå Failed to create branch {branch} after cleanup\")\n                return None\n            else:\n                print(f\"   ‚úÖ Successfully created branch {branch} after cleanup\")\n        else:\n            print(\n                f\"   ‚ùå Failed to delete existing branch {branch}: {delete_response.status_code}\"\n            )\n            return None\n\n    # Create or update file\n    file_content = base64.b64encode(content.encode()).decode()\n\n    file_data = {\n        \"message\": f\"Test commit for {title}\",\n        \"content\": file_content,\n        \"branch\": branch,\n    }\n\n    # Check if file exists in main branch first\n    success, file_info = _get_github_api(\n        f\"contents/{file_path}?ref=main\", headers, owner, repo\n    )\n    if success and file_info:\n        # File exists, need SHA for update\n        file_data[\"sha\"] = file_info[\"sha\"]\n        print(f\"   File {file_path} exists, updating with SHA\")\n    else:\n        print(f\"   Creating new file {file_path}\")\n\n    # Use PUT method for file creation/update\n    url = f\"https://api.github.com/repos/{owner}/{repo}/contents/{file_path}\"\n    try:\n        import requests\n\n        response = requests.put(url, headers=headers, json=file_data)\n        if response.status_code in [200, 201]:\n            print(f\"   ‚úÖ Successfully created/updated file {file_path}\")\n        else:\n            print(\n                f\"   ‚ùå Failed to create/update file {file_path}: {response.status_code} - {response.text}\"\n            )\n            return None\n    except Exception as e:\n        print(f\"   ‚ùå Exception creating file {file_path}: {e}\")\n        return None\n\n    # Create PR\n    pr_data = {\n        \"title\": title,\n        \"head\": branch,\n        \"base\": \"main\",\n        \"body\": f\"Test PR to validate that {title.split(':')[1].strip()} check fails correctly.\",\n    }\n\n    success, pr_response = _post_github_api(\"pulls\", headers, owner, repo, pr_data)\n    if not success:\n        print(\"   ‚ùå Failed to create PR\")\n        return None\n\n    pr_number = pr_response[\"number\"]\n    print(f\"   ‚úÖ Created test PR #{pr_number}\")\n    return pr_number\n\n\ndef _close_pr(pr_number: int, headers: Dict[str, str], owner: str, repo: str) -> bool:\n    \"\"\"Close a PR.\"\"\"\n    success, _ = _patch_github_api(\n        f\"pulls/{pr_number}\", headers, owner, repo, {\"state\": \"closed\"}\n    )\n    return success\n\n\ndef _run_unit_tests(\n    headers: Dict[str, str], owner: str, repo: str\n) -> Tuple[bool, List[str]]:\n    \"\"\"Create test PRs to verify workflow correctly fails on bad code.\"\"\"\n    print(\"\\nüß™ Running unit tests with failing PRs...\")\n    errors = []\n    created_prs = []\n\n    test_cases = [\n        {\n            \"title\": \"Test: Code Quality Failure\",\n            \"branch\": \"test-code-quality-fail\",\n            \"file_path\": \"src/lint-fail-test.js\",\n            \"content\": \"// This file contains intentional ESLint violations\\nvar unused_variable = 'this will trigger unused-vars rule'\\nconsole.log('missing semicolon - will trigger semi rule')\\nconst   badly_spaced   =   'too many spaces'\\nif(true){console.log('missing spaces around braces')}\\nfunction unusedFunction() { return 'unused'; }\\neeval('alert(\\\"dangerous eval\\\")');\\nwith (Math) { var x = cos(3 * PI) + sin(LN10) }\\nvar a = 1; var a = 2; // redeclared variable\",\n            \"expected_failure\": \"code-quality\",\n        },\n        {\n            \"title\": \"Test: Testing Suite Failure\",\n            \"branch\": \"test-testing-fail\",\n            \"file_path\": \"tests/fail-test.test.js\",\n            \"content\": \"const request = require('supertest');\\n\\ndescribe('Intentional Test Failures', () => {\\n  test('This test should always fail', () => {\\n    expect(2 + 2).toBe(5); // Intentionally wrong\\n  });\\n  \\n  test('Another failing test', () => {\\n    expect(true).toBe(false); // Intentionally wrong\\n  });\\n  \\n  test('Math failure', () => {\\n    expect(Math.max(1, 2, 3)).toBe(1); // Intentionally wrong\\n  });\\n});\",\n            \"expected_failure\": \"testing-suite\",\n        },\n        {\n            \"title\": \"Test: Security Scan Failure\",\n            \"branch\": \"test-security-fail\",\n            \"file_path\": \"src/security-fail-test.js\",\n            \"content\": \"// This file contains patterns that should trigger secret detection\\nconst hardcodedPassword = 'admin123password';\\nconst fakeApiKey = 'sk_test_' + 'fake123key456here789';\\nconst awsLikeKey = 'AKIA' + 'FAKEKEY7EXAMPLE';\\nconst dbPassword = 'password' + '=' + 'supersecret123';\\nconst tokenPattern = 'token' + '=' + 'ghp_1234567890abcdef';\\n\\n// These patterns should trigger secret detection\\nconsole.log('Password:', hardcodedPassword);\\nconsole.log('API Key:', fakeApiKey);\\nconsole.log('AWS Key:', awsLikeKey);\\nconsole.log('DB Password:', dbPassword);\\nconsole.log('Token:', tokenPattern);\\n\\nmodule.exports = {\\n  password: hardcodedPassword,\\n  apiKey: fakeApiKey\\n};\",\n            \"expected_failure\": \"security-scan\",\n        },\n        {\n            \"title\": \"Test: Build Validation Failure\",\n            \"branch\": \"test-build-fail\",\n            \"file_path\": \"src/build-fail-test.js\",\n            \"content\": \"// This file will cause build/startup failures\\nconst express = require('express');\\nconst nonExistentModule = require('this-module-does-not-exist-anywhere');\\nconst anotherMissing = require('@fake/missing-package');\\n\\n// This will cause runtime errors during startup\\nconst app = express();\\n\\n// Define a route that will cause issues\\napp.get('/test', (req, res) => {\\n  // Try to use non-existent modules\\n  nonExistentModule.doSomething();\\n  anotherMissing.initialize();\\n  res.send('This should never work');\\n});\\n\\n// Override the listen method to always fail\\nconst originalListen = app.listen;\\napp.listen = function(port, callback) {\\n  console.log('Attempting to start server...');\\n  // This will crash during build validation\\n  throw new Error('Intentional build failure for testing');\\n};\\n\\nmodule.exports = app;\",\n            \"expected_failure\": \"build-validation\",\n        },\n    ]\n\n    for test_case in test_cases:\n        pr_number = _create_test_pr(\n            test_case[\"title\"],\n            test_case[\"branch\"],\n            test_case[\"content\"],\n            test_case[\"file_path\"],\n            headers,\n            owner,\n            repo,\n        )\n\n        if pr_number:\n            created_prs.append(pr_number)\n        else:\n            errors.append(f\"Failed to create test PR: {test_case['title']}\")\n\n    if created_prs:\n        print(f\"   Created {len(created_prs)} test PRs, waiting for workflows...\")\n\n        # Wait a bit for workflows to start\n        time.sleep(5)\n\n        # Wait for workflows to complete\n        _wait_for_workflow_completion(\n            headers, owner, repo, \"pr-automation.yml\", max_wait=300\n        )\n\n        # Verify each test PR failed appropriately\n        for i, pr_number in enumerate(created_prs):\n            test_case = test_cases[i]\n            print(\n                f\"   Checking test PR #{pr_number} ({test_case['expected_failure']} failure)...\"\n            )\n\n            # Get workflow runs for this PR\n            success, runs_response = _get_github_api(\n                \"actions/runs?event=pull_request&per_page=20\", headers, owner, repo\n            )\n\n            if success:\n                pr_runs = []\n                for run in runs_response.get(\"workflow_runs\", []):\n                    # Check pull_requests field\n                    for pr in run.get(\"pull_requests\", []):\n                        if pr.get(\"number\") == pr_number:\n                            pr_runs.append(run)\n                            break\n\n                # If no runs found via pull_requests, try matching by branch\n                if not pr_runs:\n                    branch_name = test_case[\"branch\"]\n                    for run in runs_response.get(\"workflow_runs\", []):\n                        if run.get(\"head_branch\") == branch_name:\n                            pr_runs.append(run)\n\n                if pr_runs:\n                    latest_run = pr_runs[0]\n                    if latest_run[\"conclusion\"] != \"failure\":\n                        errors.append(\n                            f\"Test PR #{pr_number} should have failed but got: {latest_run['conclusion']}\"\n                        )\n                    else:\n                        print(f\"   ‚úÖ Test PR #{pr_number} correctly failed\")\n                else:\n                    errors.append(f\"No workflow runs found for test PR #{pr_number}\")\n\n        # Clean up test PRs and branches\n        print(\"   Cleaning up test PRs and branches...\")\n        for i, pr_number in enumerate(created_prs):\n            if _close_pr(pr_number, headers, owner, repo):\n                print(f\"   ‚úÖ Closed test PR #{pr_number}\")\n            else:\n                print(f\"   ‚ö†Ô∏è Failed to close test PR #{pr_number}\")\n\n            # Delete test branch\n            branch_name = test_cases[i][\"branch\"]\n            import requests\n\n            url = f\"https://api.github.com/repos/{owner}/{repo}/git/refs/heads/{branch_name}\"\n            response = requests.delete(url, headers=headers)\n            if response.status_code == 204:\n                print(f\"   ‚úÖ Deleted test branch {branch_name}\")\n            else:\n                print(f\"   ‚ö†Ô∏è Failed to delete test branch {branch_name}\")\n\n    return len(errors) == 0, errors\n\n\ndef verify() -> bool:\n    \"\"\"\n    Verify that the PR automation workflow is working correctly.\n    \"\"\"\n    load_dotenv(\".mcp_env\")\n\n    github_token = os.environ.get(\"MCP_GITHUB_TOKEN\")\n    if not github_token:\n        print(\"Error: MCP_GITHUB_TOKEN environment variable not set\", file=sys.stderr)\n        return False\n\n    github_org = os.environ.get(\"GITHUB_EVAL_ORG\")\n    if not github_org:\n        print(\"Error: GITHUB_EVAL_ORG environment variable not set\", file=sys.stderr)\n        return False\n\n    owner = github_org\n    repo = \"mcpmark-cicd\"\n\n    headers = {\n        \"Authorization\": f\"token {github_token}\",\n        \"Accept\": \"application/vnd.github.v3+json\",\n    }\n\n    print(\"üîç Starting PR Automation Workflow Verification\")\n    print(\"=\" * 60)\n\n    all_passed = True\n\n    # 1. Verify workflow file exists\n    workflow_ok, workflow_errors = _verify_workflow_file(headers, owner, repo)\n    if not workflow_ok:\n        all_passed = False\n        print(\"‚ùå Workflow File Verification Failed:\")\n        for error in workflow_errors:\n            print(f\"   - {error}\")\n    else:\n        print(\"‚úÖ Workflow File Verification Passed\")\n\n    # 2. Verify main PR was merged\n    pr_ok, pr_errors, pr_data = _verify_main_pr_merged(headers, owner, repo)\n    if not pr_ok:\n        all_passed = False\n        print(\"‚ùå Main PR Verification Failed:\")\n        for error in pr_errors:\n            print(f\"   - {error}\")\n    else:\n        print(\"‚úÖ Main PR Verification Passed\")\n\n    # 3. Verify workflow runs (only if PR verification passed)\n    if pr_ok and pr_data:\n        runs_ok, runs_errors = _verify_workflow_runs(pr_data, headers, owner, repo)\n        if not runs_ok:\n            all_passed = False\n            print(\"‚ùå Workflow Runs Verification Failed:\")\n            for error in runs_errors:\n                print(f\"   - {error}\")\n        else:\n            print(\"‚úÖ Workflow Runs Verification Passed\")\n\n        # 4. Verify PR comments\n        comments_ok, comments_errors = _verify_pr_comments(\n            pr_data, headers, owner, repo\n        )\n        if not comments_ok:\n            all_passed = False\n            print(\"‚ùå PR Comments Verification Failed:\")\n            for error in comments_errors:\n                print(f\"   - {error}\")\n        else:\n            print(\"‚úÖ PR Comments Verification Passed\")\n\n    # 5. Run unit tests with failing PRs\n    tests_ok, tests_errors = _run_unit_tests(headers, owner, repo)\n    if not tests_ok:\n        all_passed = False\n        print(\"‚ùå Unit Tests Failed:\")\n        for error in tests_errors:\n            print(f\"   - {error}\")\n    else:\n        print(\"‚úÖ Unit Tests Passed\")\n\n    print(\"\\n\" + \"=\" * 60)\n    if all_passed:\n        print(\"üéâ All PR Automation Workflow verifications PASSED!\")\n        print(\"\\nüìã Summary:\")\n        print(\"   ‚úÖ Workflow file exists with correct triggers and 4 parallel jobs\")\n        print(\"   ‚úÖ Main PR was merged from pr-automation-workflow to main\")\n        print(\"   ‚úÖ Workflow runs show all 4 jobs executed in parallel and succeeded\")\n        print(\"   ‚úÖ PR comments contain required automation reports\")\n        print(\"   ‚úÖ Unit tests confirmed workflow correctly fails on problematic code\")\n        print(\"\\nü§ñ The GitHub Actions PR automation workflow is working correctly!\")\n    else:\n        print(\"‚ùå PR Automation Workflow verification FAILED!\")\n        print(\"   Some components did not meet the expected automation requirements.\")\n\n    return all_passed\n\n\nif __name__ == \"__main__\":\n    success = verify()\n    sys.exit(0 if success else 1)\n"
}