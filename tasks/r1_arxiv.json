{
  "task_id": "r1_arxiv",
  "task_name": "R1 Arxiv",
  "category_id": "web_search",
  "category_name": "Web Search",
  "description": "Search arXiv for R1 model research papers, extract technical specifications, analyze methodology sections, compile research findings, and generate comprehensive literature review.",
  "author": "Arvin Xu",
  "created_at": "2025-08-18",
  "difficulty": "L3",
  "tags": [
    "search aggregation",
    "data extraction",
    "comparative analysis",
    "content submission"
  ],
  "mcp": [
    "playwright"
  ],
  "meta_data": {
    "stateType": null,
    "stateContent": null,
    "stateUrl": null,
    "stateOriginalUrl": null
  },
  "instruction": "# Web Search Task\n\nUse Playwright MCP tools to search for the DeepSeek R1 research paper and extract all the paragraphs of the Conclusion section.\n\n## Requirements:\n\n1. Search for the DeepSeek R1 research paper\n2. Navigate to the paper and find the Conclusion section\n3. Extract **ALL the paragraphs** of the Conclusion section\n4. **Provide the content in Markdown format - no explanations, no additional text**\n\n## Important Notes:\n\n- **Output ALL the paragraphs of text**\n- **Do NOT include any explanations, summaries, or additional content**\n- **The response should contain ONLY the Conclusion section content formatted in Markdown**\n\n## Expected Output:\nAll the paragraphs of the Conclusion section from the DeepSeek R1 paper, formatted in Markdown with proper paragraph structure and formatting.\n",
  "verify": "#!/usr/bin/env python3\n\"\"\"\nVerification script for Playwright web search task.\n\nSimple verification that checks if the AI agent found the correct Introduction content.\nThe expected ground truth answer is configured at the top of the file.\n\"\"\"\n\nimport sys\nimport json\nimport os\nfrom pathlib import Path\nfrom typing import Dict, Any\n\n# =============================================================================\n# CONFIGURATION\n# =============================================================================\n\n# Expected ground truth content from content.txt\nEXPECTED_CONTENT_FILE = \"content.txt\"\n\n# =============================================================================\n# MCP RESULT PARSING\n# =============================================================================\n\n\ndef get_working_directory() -> Path:\n    \"\"\"Get the working directory where messages.json should be.\"\"\"\n    # Priority 1: Use MCP_MESSAGES path if available (most reliable)\n    messages_path = os.getenv(\"MCP_MESSAGES\")\n    if messages_path and Path(messages_path).exists():\n        return Path(messages_path).parent.resolve()\n\n    # Priority 2: Use PLAYWRIGHT_WORK_DIR environment variable\n    work_dir = os.getenv(\"PLAYWRIGHT_WORK_DIR\")\n    if work_dir:\n        work_path = Path(work_dir).resolve()\n        if (work_path / \"messages.json\").exists():\n            return work_path\n\n    # Priority 3: Check current directory (fallback)\n    current_dir = Path.cwd()\n    if (current_dir / \"messages.json\").exists():\n        return current_dir\n\n    # Priority 4: Default fallback\n    return Path(\".\").resolve()\n\n\ndef load_expected_content() -> str:\n    \"\"\"Load the expected content from content.txt\"\"\"\n    # content.txt is in the same directory as verify.py\n    current_file = Path(__file__).resolve()\n    content_file = current_file.parent / EXPECTED_CONTENT_FILE\n\n    if not content_file.exists():\n        print(f\"| {EXPECTED_CONTENT_FILE} not found at: {content_file}\")\n        return \"\"\n\n    print(f\"| Found {EXPECTED_CONTENT_FILE} at: {content_file}\")\n\n    try:\n        with open(content_file, \"r\", encoding=\"utf-8\") as f:\n            return f.read().strip()\n    except (IOError, UnicodeDecodeError) as e:\n        print(f\"| Warning: Could not read {content_file}: {e}\")\n        return \"\"\n\n\ndef parse_ai_results(work_dir: Path) -> Dict[str, Any]:\n    \"\"\"Parse the AI agent's results from messages.json\"\"\"\n    messages_file = work_dir / \"messages.json\"\n    if not messages_file.exists():\n        return {\"success\": False, \"error\": \"No messages.json found\"}\n\n    try:\n        with open(messages_file, \"r\", encoding=\"utf-8\") as f:\n            messages = json.load(f)\n    except (json.JSONDecodeError, IOError) as e:\n        return {\"success\": False, \"error\": f\"Failed to read messages.json: {e}\"}\n\n    # Look for extracted content in the AI's responses\n    found_content = False\n    ai_responses = []\n    extracted_content = \"\"\n\n    for message in messages:\n        if message.get(\"role\") == \"assistant\":\n            content = str(message.get(\"content\", \"\"))\n\n            # Handle both string and list content formats\n            if isinstance(message.get(\"content\"), list):\n                content = \" \".join(\n                    item.get(\"text\", \"\") if isinstance(item, dict) else str(item)\n                    for item in message.get(\"content\", [])\n                )\n\n            ai_responses.append(content)\n\n            # Store the last response as extracted content\n            extracted_content = content\n\n    return {\n        \"success\": True,\n        \"found_content\": True,  # Assuming content was found if we have responses\n        \"ai_responses\": ai_responses,\n        \"extracted_content\": extracted_content,\n        \"total_responses\": len(ai_responses),\n    }\n\n\ndef compare_content(extracted: str, expected: str) -> Dict[str, Any]:\n    \"\"\"Compare extracted content with expected content\"\"\"\n    if not expected:\n        return {\"success\": False, \"error\": \"No expected content to compare against\"}\n\n    if not extracted:\n        return {\"success\": False, \"error\": \"No extracted content found\"}\n\n    # Normalize content for comparison (remove extra whitespace, normalize line breaks)\n    extracted_normalized = \" \".join(extracted.split())\n    expected_normalized = \" \".join(expected.split())\n\n    # Direct text comparison - content must be exactly the same\n    is_exact_match = extracted_normalized == expected_normalized\n\n    return {\n        \"success\": True,\n        \"is_exact_match\": is_exact_match,\n        \"extracted_length\": len(extracted_normalized),\n        \"expected_length\": len(expected_normalized),\n        \"extracted_preview\": extracted_normalized[:100] + \"...\" if len(extracted_normalized) > 100 else extracted_normalized,\n        \"expected_preview\": expected_normalized[:100] + \"...\" if len(expected_normalized) > 100 else expected_normalized\n    }\n\n\n# =============================================================================\n# MAIN VERIFICATION\n# =============================================================================\n\n\ndef verify_task(work_dir: Path) -> bool:\n    \"\"\"Verify the AI agent found the correct Introduction content\"\"\"\n    print(\"| Verifying Playwright Web Search Task - DeepSeek R1 Introduction\")\n    print(\"| \" + \"=\" * 70)\n\n    # Load expected content\n    print(\"| Loading expected content...\")\n    expected_content = load_expected_content()\n\n    if not expected_content:\n        print(\"| Error: Could not load expected content\")\n        return False\n\n    print(f\"| Expected content loaded ({len(expected_content)} characters)\")\n\n    # Parse MCP messages\n    messages = parse_ai_results(work_dir)\n\n    if not messages[\"success\"]:\n        print(f\"| Error: Could not parse AI results: {messages.get('error')}\")\n        return False\n\n    # Extract AI agent response\n    extracted_content = messages.get(\"extracted_content\", \"\")\n\n    if not extracted_content:\n        print(\"| Error: No AI agent response found\")\n        return False\n\n    print(f\"| Extracted content: {len(extracted_content)} characters\")\n\n    # Compare content\n    print(\"| Comparing extracted content with expected content...\")\n    comparison = compare_content(extracted_content, expected_content)\n\n    if not comparison[\"success\"]:\n        print(f\"| Comparison failed: {comparison.get('error')}\")\n        return False\n\n    print(f\"| Content comparison results:\")\n    print(f\"|   - Extracted length: {comparison['extracted_length']} characters\")\n    print(f\"|   - Expected length: {comparison['expected_length']} characters\")\n    print(f\"|   - Extracted preview: {comparison['extracted_preview']}\")\n    print(f\"|   - Expected preview: {comparison['expected_preview']}\")\n\n    if comparison['is_exact_match']:\n        print(\"| Task completed successfully! Content matches exactly.\")\n        return True\n    else:\n        print(\"| Task verification failed. Content does not match exactly.\")\n        return False\n\n\ndef main():\n    \"\"\"Main verification function\"\"\"\n    print(\"| Starting verification...\")\n\n    # Get working directory\n    work_dir = get_working_directory()\n    print(f\"| Working directory: {work_dir}\")\n\n    # Run verification\n    success = verify_task(work_dir)\n\n    if success:\n        sys.exit(0)\n    else:\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n"
}