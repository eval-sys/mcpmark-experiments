{
  "task_id": "dataset_comparison",
  "task_name": "Dataset Comparison",
  "category_id": "votenet",
  "category_name": "Votenet",
  "description": "Map ScanNet object categories to their SUN RGB-D equivalents and calculate detailed object counts for each mapped category.",
  "author": "Lingjun Chen",
  "created_at": "2025-08-13",
  "difficulty": "L3",
  "tags": [
    "cross-referencing",
    "data extraction",
    "pattern analysis"
  ],
  "mcp": [
    "filesystem"
  ],
  "meta_data": {
    "stateType": "text",
    "stateContent": "votenet/\n    ‚îú‚îÄ‚îÄ doc/\n    ‚îÇ       ‚îú‚îÄ‚îÄ teaser.jpg\n    ‚îÇ       ‚îî‚îÄ‚îÄ tips.md\n    ‚îú‚îÄ‚îÄ models/\n    ‚îÇ       ‚îú‚îÄ‚îÄ ap_helper.py\n    ‚îÇ       ‚îú‚îÄ‚îÄ backbone_module.py\n    ‚îÇ       ‚îú‚îÄ‚îÄ boxnet.py\n    ‚îÇ       ‚îú‚îÄ‚îÄ dump_helper.py\n    ‚îÇ       ‚îú‚îÄ‚îÄ loss_helper.py\n    ‚îÇ       ‚îú‚îÄ‚îÄ loss_helper_boxnet.py\n    ‚îÇ       ‚îú‚îÄ‚îÄ proposal_module.py\n    ‚îÇ       ‚îú‚îÄ‚îÄ votenet.py\n    ‚îÇ       ‚îî‚îÄ‚îÄ voting_module.py\n    ‚îú‚îÄ‚îÄ pointnet2/\n    ‚îÇ       ‚îú‚îÄ‚îÄ _ext_src/\n    ‚îÇ       ‚îÇ       ‚îú‚îÄ‚îÄ include/\n    ‚îÇ       ‚îÇ       ‚îÇ       ‚îú‚îÄ‚îÄ ball_query.h\n    ‚îÇ       ‚îÇ       ‚îÇ       ‚îú‚îÄ‚îÄ cuda_utils.h\n    ‚îÇ       ‚îÇ       ‚îÇ       ‚îú‚îÄ‚îÄ group_points.h\n    ‚îÇ       ‚îÇ       ‚îÇ       ‚îú‚îÄ‚îÄ interpolate.h\n    ‚îÇ       ‚îÇ       ‚îÇ       ‚îú‚îÄ‚îÄ sampling.h\n    ‚îÇ       ‚îÇ       ‚îÇ       ‚îî‚îÄ‚îÄ utils.h\n    ‚îÇ       ‚îÇ       ‚îî‚îÄ‚îÄ src/\n    ‚îÇ       ‚îÇ               ‚îú‚îÄ‚îÄ ball_query.cpp\n    ‚îÇ       ‚îÇ               ‚îú‚îÄ‚îÄ ball_query_gpu.cu\n    ‚îÇ       ‚îÇ               ‚îú‚îÄ‚îÄ bindings.cpp\n    ‚îÇ       ‚îÇ               ‚îú‚îÄ‚îÄ group_points.cpp\n    ‚îÇ       ‚îÇ               ‚îú‚îÄ‚îÄ group_points_gpu.cu\n    ‚îÇ       ‚îÇ               ‚îú‚îÄ‚îÄ interpolate.cpp\n    ‚îÇ       ‚îÇ               ‚îú‚îÄ‚îÄ interpolate_gpu.cu\n    ‚îÇ       ‚îÇ               ‚îú‚îÄ‚îÄ sampling.cpp\n    ‚îÇ       ‚îÇ               ‚îî‚îÄ‚îÄ sampling_gpu.cu\n    ‚îÇ       ‚îú‚îÄ‚îÄ pointnet2_modules.py\n    ‚îÇ       ‚îú‚îÄ‚îÄ pointnet2_test.py\n    ‚îÇ       ‚îú‚îÄ‚îÄ pointnet2_utils.py\n    ‚îÇ       ‚îú‚îÄ‚îÄ pytorch_utils.py\n    ‚îÇ       ‚îî‚îÄ‚îÄ setup.py\n    ‚îú‚îÄ‚îÄ scannet/\n    ‚îÇ       ‚îú‚îÄ‚îÄ meta_data/\n    ‚îÇ       ‚îÇ       ‚îú‚îÄ‚îÄ scannet_means.npz\n    ‚îÇ       ‚îÇ       ‚îú‚îÄ‚îÄ scannet_train.txt\n    ‚îÇ       ‚îÇ       ‚îú‚îÄ‚îÄ scannetv2-labels.combined.tsv\n    ‚îÇ       ‚îÇ       ‚îú‚îÄ‚îÄ scannetv2_test.txt\n    ‚îÇ       ‚îÇ       ‚îú‚îÄ‚îÄ scannetv2_train.txt\n    ‚îÇ       ‚îÇ       ‚îî‚îÄ‚îÄ scannetv2_val.txt\n    ‚îÇ       ‚îú‚îÄ‚îÄ scans/\n    ‚îÇ       ‚îú‚îÄ‚îÄ batch_load_scannet_data.py\n    ‚îÇ       ‚îú‚îÄ‚îÄ data_viz.py\n    ‚îÇ       ‚îú‚îÄ‚îÄ load_scannet_data.py\n    ‚îÇ       ‚îú‚îÄ‚îÄ model_util_scannet.py\n    ‚îÇ       ‚îú‚îÄ‚îÄ README.md\n    ‚îÇ       ‚îú‚îÄ‚îÄ scannet_detection_dataset.py\n    ‚îÇ       ‚îî‚îÄ‚îÄ scannet_utils.py\n    ‚îú‚îÄ‚îÄ sunrgbd/\n    ‚îÇ       ‚îú‚îÄ‚îÄ matlab/\n    ‚îÇ       ‚îÇ       ‚îú‚îÄ‚îÄ extract_rgbd_data_v1.m\n    ‚îÇ       ‚îÇ       ‚îú‚îÄ‚îÄ extract_rgbd_data_v2.m\n    ‚îÇ       ‚îÇ       ‚îî‚îÄ‚îÄ extract_split.m\n    ‚îÇ       ‚îú‚îÄ‚îÄ OFFICIAL_SUNRGBD/\n    ‚îÇ       ‚îú‚îÄ‚îÄ sunrgbd_trainval/\n    ‚îÇ       ‚îú‚îÄ‚îÄ model_util_sunrgbd.py\n    ‚îÇ       ‚îú‚îÄ‚îÄ README.md\n    ‚îÇ       ‚îú‚îÄ‚îÄ sunrgbd_data.py\n    ‚îÇ       ‚îú‚îÄ‚îÄ sunrgbd_detection_dataset.py\n    ‚îÇ       ‚îî‚îÄ‚îÄ sunrgbd_utils.py\n    ‚îú‚îÄ‚îÄ utils/\n    ‚îÇ       ‚îú‚îÄ‚îÄ box_util.py\n    ‚îÇ       ‚îú‚îÄ‚îÄ eval_det.py\n    ‚îÇ       ‚îú‚îÄ‚îÄ metric_util.py\n    ‚îÇ       ‚îú‚îÄ‚îÄ nms.py\n    ‚îÇ       ‚îú‚îÄ‚îÄ nn_distance.py\n    ‚îÇ       ‚îú‚îÄ‚îÄ pc_util.py\n    ‚îÇ       ‚îú‚îÄ‚îÄ tf_logger.py\n    ‚îÇ       ‚îî‚îÄ‚îÄ tf_visualizer.py\n    ‚îú‚îÄ‚îÄ CODE_OF_CONDUCT.md\n    ‚îú‚îÄ‚îÄ CONTRIBUTING.md\n    ‚îú‚îÄ‚îÄ demo.py\n    ‚îú‚îÄ‚îÄ eval.py\n    ‚îú‚îÄ‚îÄ LICENSE\n    ‚îú‚îÄ‚îÄ README.md\n    ‚îî‚îÄ‚îÄ train.py",
    "stateUrl": "https://storage.mcpmark.ai/filesystem/votenet.zip",
    "stateOriginalUrl": "https://github.com/facebookresearch/votenet"
  },
  "instruction": "Please use FileSystem tools to finish the following task:\n\n### Task Description\n\nAnalyze the codebase to map ScanNet object categories to SUN RGB-D categories and calculate object counts.\n\n### Task Objectives\n\n1. **Primary Goal**: Use SUN RGB-D's 10-category classification system as the target taxonomy\n2. **Mapping Requirement**: Map each ScanNet object category (using the \"category\" field, not \"raw_category\") to the corresponding SUN RGB-D category\n3. **Calculation**: For each SUN RGB-D category, calculate the total count of objects from ScanNet that map to that category ÔºàIt only counts if the category (not raw category) name are exactly the same(night_stand = nightstand)Ôºâ\n4. **Output**: Generate an analysis.txt file in the main directory showing the mapping and counts\n\n### Expected Output\n\nCreate a file named `analysis.txt` in the test directory root with the following format:\n\n- Each SUN RGB-D category should be represented as a 2-line block\n- Line 1: category name\n- Line 2: total count\n- Each block should be separated by one empty line\n",
  "verify": "#!/usr/bin/env python3\n\"\"\"\nVerification script for Votenet Dataset Comparison Task\n\"\"\"\n\nimport sys\nfrom pathlib import Path\nimport re\nimport os\n\ndef get_test_directory() -> Path:\n    \"\"\"Get the test directory from FILESYSTEM_TEST_DIR env var.\"\"\"\n    test_root = os.environ.get(\"FILESYSTEM_TEST_DIR\")\n    if not test_root:\n        raise ValueError(\"FILESYSTEM_TEST_DIR environment variable is required\")\n    return Path(test_root)\n\ndef verify_analysis_file_exists(test_dir: Path) -> bool:\n    \"\"\"Verify that the analysis.txt file exists.\"\"\"\n    analysis_file = test_dir / \"analysis.txt\"\n    \n    if not analysis_file.exists():\n        print(\"‚ùå File 'analysis.txt' not found\")\n        return False\n    \n    print(\"‚úÖ Analysis file found\")\n    return True\n\ndef verify_analysis_format(test_dir: Path) -> bool:\n    \"\"\"Verify that the analysis file has the correct format.\"\"\"\n    analysis_file = test_dir / \"analysis.txt\"\n    \n    try:\n        content = analysis_file.read_text()\n        lines = content.split('\\n')\n        \n        # Check if content is not empty\n        if not content.strip():\n            print(\"‚ùå Analysis file is empty\")\n            return False\n        \n        # Check if we have enough lines for at least one category block\n        if len(lines) < 2:\n            print(\"‚ùå Analysis file doesn't have enough lines for a category block\")\n            return False\n        \n        # Check if the format follows the 2-line block pattern with empty lines between blocks\n        # Each block should have: category_name, count, empty_line\n        line_index = 0\n        block_count = 0\n        \n        while line_index < len(lines):\n            # Skip leading empty lines\n            while line_index < len(lines) and lines[line_index].strip() == \"\":\n                line_index += 1\n            \n            if line_index >= len(lines):\n                break\n            \n            # Check if we have at least 2 lines for a block\n            if line_index + 1 >= len(lines):\n                print(\"‚ùå Incomplete category block at the end\")\n                return False\n            \n            # Line 1 should be category name\n            category_line = lines[line_index].strip()\n            if not category_line:\n                print(f\"‚ùå Empty category name at line {line_index + 1}\")\n                return False\n            \n            # Line 2 should be count\n            count_line = lines[line_index + 1].strip()\n            if not count_line:\n                print(f\"‚ùå Empty count at line {line_index + 2}\")\n                return False\n            \n            # Check if count line contains a number\n            if not re.search(r'\\d+', count_line):\n                print(f\"‚ùå Count line doesn't contain a number at line {line_index + 2}: '{count_line}'\")\n                return False\n            \n            block_count += 1\n            line_index += 2\n            \n            # Skip empty line between blocks (if not at the end)\n            if line_index < len(lines) and lines[line_index].strip() == \"\":\n                line_index += 1\n        \n        if block_count == 0:\n            print(\"‚ùå No valid category blocks found\")\n            return False\n        \n        print(f\"‚úÖ Analysis format is correct with {block_count} category blocks\")\n        return True\n        \n    except Exception as e:\n        print(f\"‚ùå Error reading analysis file: {e}\")\n        return False\n\ndef verify_required_categories(test_dir: Path) -> bool:\n    \"\"\"Verify that all required SUN RGB-D categories are present.\"\"\"\n    analysis_file = test_dir / \"analysis.txt\"\n    \n    try:\n        content = analysis_file.read_text()\n        lines = content.split('\\n')\n        \n        # Extract category names from the file\n        categories_found = []\n        line_index = 0\n        \n        while line_index < len(lines):\n            # Skip empty lines\n            while line_index < len(lines) and lines[line_index].strip() == \"\":\n                line_index += 1\n            \n            if line_index >= len(lines):\n                break\n            \n            # Get category name\n            category_line = lines[line_index].strip()\n            if category_line:\n                categories_found.append(category_line.lower())\n            \n            # Skip to next block\n            line_index += 2\n            while line_index < len(lines) and lines[line_index].strip() == \"\":\n                line_index += 1\n        \n        # Required categories\n        required_categories = {\n            'chair', 'table', 'bed', 'bookshelf', 'desk', \n            'toilet', 'dresser', 'bathtub', 'sofa', 'night_stand'\n        }\n        \n        # Check if all required categories are present\n        missing_categories = required_categories - set(categories_found)\n        if missing_categories:\n            print(f\"‚ùå Missing required categories: {missing_categories}\")\n            return False\n        \n        # Check for extra categories\n        extra_categories = set(categories_found) - required_categories\n        if extra_categories:\n            print(f\"‚ö†Ô∏è  Extra categories found: {extra_categories}\")\n        \n        print(f\"‚úÖ All required categories present: {sorted(required_categories)}\")\n        return True\n        \n    except Exception as e:\n        print(f\"‚ùå Error verifying required categories: {e}\")\n        return False\n\ndef verify_category_counts(test_dir: Path) -> bool:\n    \"\"\"Verify that the category counts match the expected values.\"\"\"\n    analysis_file = test_dir / \"analysis.txt\"\n    \n    try:\n        content = analysis_file.read_text()\n        lines = content.split('\\n')\n        \n        # Expected counts from answer.txt\n        expected_counts = {\n            'chair': 4681,\n            'table': 1170,\n            'bed': 370,\n            'bookshelf': 377,\n            'desk': 680,\n            'toilet': 256,\n            'dresser': 213,\n            'bathtub': 144,\n            'sofa': 1,\n            'night_stand': 224\n        }\n        \n        # Extract category counts from the file\n        category_counts = {}\n        line_index = 0\n        \n        while line_index < len(lines):\n            # Skip empty lines\n            while line_index < len(lines) and lines[line_index].strip() == \"\":\n                line_index += 1\n            \n            if line_index >= len(lines):\n                break\n            \n            # Get category name\n            category_line = lines[line_index].strip()\n            if not category_line:\n                line_index += 1\n                continue\n            \n            # Get count\n            if line_index + 1 < len(lines):\n                count_line = lines[line_index + 1].strip()\n                if count_line:\n                    # Extract number from count line\n                    count_match = re.search(r'(\\d+)', count_line)\n                    if count_match:\n                        category = category_line.lower()\n                        count = int(count_match.group(1))\n                        category_counts[category] = count\n            \n            # Skip to next block\n            line_index += 2\n            while line_index < len(lines) and lines[line_index].strip() == \"\":\n                line_index += 1\n        \n        # Verify counts match expected values\n        all_counts_correct = True\n        for category, expected_count in expected_counts.items():\n            if category in category_counts:\n                actual_count = category_counts[category]\n                if actual_count != expected_count:\n                    print(f\"‚ùå Count mismatch for {category}: expected {expected_count}, got {actual_count}\")\n                    all_counts_correct = False\n            else:\n                print(f\"‚ùå Category {category} not found in analysis\")\n                all_counts_correct = False\n        \n        if all_counts_correct:\n            print(\"‚úÖ All category counts match expected values\")\n            return True\n        else:\n            return False\n        \n    except Exception as e:\n        print(f\"‚ùå Error verifying category counts: {e}\")\n        return False\n\ndef verify_file_structure(test_dir: Path) -> bool:\n    \"\"\"Verify that the analysis.txt file is in the correct location.\"\"\"\n    analysis_file = test_dir / \"analysis.txt\"\n    \n    if not analysis_file.exists():\n        print(\"‚ùå Analysis file not found in test directory root\")\n        return False\n    \n    # Check if it's directly in the test directory root, not in a subdirectory\n    if analysis_file.parent != test_dir:\n        print(\"‚ùå Analysis file should be in the test directory root\")\n        return False\n    \n    print(\"‚úÖ Analysis file is in the correct location\")\n    return True\n\ndef main():\n    \"\"\"Main verification function.\"\"\"\n    test_dir = get_test_directory()\n    print(\"üîç Verifying Votenet Dataset Comparison Task...\")\n    \n    # Define verification steps\n    verification_steps = [\n        (\"Analysis File Exists\", verify_analysis_file_exists),\n        (\"File Location\", verify_file_structure),\n        (\"File Format\", verify_analysis_format),\n        (\"Required Categories\", verify_required_categories),\n        (\"Category Counts\", verify_category_counts),\n    ]\n    \n    # Run all verification steps\n    all_passed = True\n    for step_name, verify_func in verification_steps:\n        print(f\"\\n--- {step_name} ---\")\n        if not verify_func(test_dir):\n            all_passed = False\n    \n    # Final result\n    print(\"\\n\" + \"=\"*50)\n    if all_passed:\n        print(\"‚úÖ Votenet dataset comparison task completed correctly!\")\n        print(\"üéâ Task verification: PASS\")\n        sys.exit(0)\n    else:\n        print(\"‚ùå Task verification: FAIL\")\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()"
}