{
  "task_id": "health_routine_optimization",
  "task_name": "Health Routine Optimization",
  "category_id": "shopping",
  "category_name": "Shopping",
  "description": "Optimize health and wellness product selections by analyzing nutritional supplements, fitness equipment, creating personalized routines, and tracking health metrics for lifestyle improvements.",
  "author": "Yaoqi Ye",
  "created_at": "2025-08-17",
  "difficulty": "L3",
  "tags": [
    "data extraction",
    "comparative analysis",
    "content submission"
  ],
  "mcp": [
    "playwright"
  ],
  "meta_data": {
    "stateType": "video",
    "stateContent": null,
    "stateUrl": "https://storage.mcpmark.ai/tasks_state/playwright_video/one-stop-market.mp4",
    "stateOriginalUrl": "https://github.com/web-arena-x/webarena/tree/main/environment_docker"
  },
  "instruction": "\n\n## Task Requirements\n\n1. Search for products with `vitamin` in Description and price range `$0.00` to `$99.99`. Record total search results count.\n\n2. In \"Health & Household\" category with price filter `$0.00 - $99.99`:\n   - Add \"LOOPACELL AG13 LR44 L1154 357 76A A76 Button Cell Battery 10 Pack\" to comparison\n   - Add \"Energizer MAX C Batteries, Premium Alkaline C Cell Batteries (8 Battery Count)\" to comparison\n   - Record each battery's price\n   - Verify comparison list has 2 items\n\n3. Search `Elmwood Inn Fine Teas`, find \"Elmwood Inn Fine Teas, Orange Vanilla Caffeine-free Fruit Infusion, 16-Ounce Pouch\":\n   - Record SKU, rating percentage, and review count\n   - Add to cart with quantity 2\n\n4. Search `energy`, sort by Relevance (descending):\n   - Find \"V8 +Energy, Healthy Energy Drink, Steady Energy from Black and Green Tea, Pomegranate Blueberry, 8 Ounce Can ,Pack of 24\"\n   - Record its position (1st, 2nd, 3rd, etc.)\n   - Add to cart with quantity 1\n\n5. In cart:\n   - Record unique products count, total quantity, and subtotal\n   - Then update Elmwood tea quantity to 3\n   - Record new subtotal\n\n## Output Format\n\n```\n<answer>\nAdvancedSearchResults|XXXX\nBattery1Name|LOOPACELL AG13 LR44\nBattery1Price|$X.XX\nBattery2Name|Energizer MAX C\nBattery2Price|$XX.XX\nComparisonCount|X\nTeaSKU|XXXXXXXXXX\nTeaRating|XXX%\nTeaReviews|X\nV8Position|Xth\nCartUniqueProducts|X\nCartTotalQuantity|X\nInitialSubtotal|$XX.XX\nFinalSubtotal|$XX.XX\n</answer>\n```\n\n",
  "verify": "\nimport asyncio\nimport sys\nimport os\nimport json\nimport re\nfrom pathlib import Path\n\n\ndef get_model_response():\n    \"\"\"\n    Get the model's response from the MCP_MESSAGES environment variable.\n    Returns the last assistant message text.\n    \"\"\"\n    messages_path = os.getenv(\"MCP_MESSAGES\")\n    print(f\"MCP_MESSAGES: {messages_path}\")\n    if not messages_path:\n        print(\"Warning: MCP_MESSAGES environment variable not set\", file=sys.stderr)\n        return None\n\n    try:\n        with open(messages_path, \"r\") as f:\n            messages = json.load(f)\n\n        # Find the last assistant message\n        for message in reversed(messages):\n            if (\n                message.get(\"role\") == \"assistant\"\n                and message.get(\"status\") == \"completed\"\n                and message.get(\"type\") == \"message\"\n            ):\n                content = message.get(\"content\", [])\n                for item in content:\n                    if item.get(\"type\") == \"output_text\":\n                        return item.get(\"text\", \"\")\n\n        print(\"Warning: No assistant response found in messages\", file=sys.stderr)\n        return None\n    except Exception as e:\n        print(f\"Error reading messages file: {str(e)}\", file=sys.stderr)\n        return None\n\ndef parse_answer_format(text):\n    \"\"\"\n    Parse the <answer>...</answer> format from the agent's output.\n    Returns a dictionary with the parsed values.\n    \"\"\"\n    if not text:\n        return None\n\n    # Look for <answer>...</answer> pattern\n    match = re.search(r\"<answer>(.*?)</answer>\", text, re.IGNORECASE | re.DOTALL)\n    if not match:\n        return None\n\n    answer_content = match.group(1).strip()\n\n    # Parse each line\n    result = {}\n    lines = answer_content.split(\"\\n\")\n\n    if len(lines) != 14:\n        print(f\"Error: Expected 14 lines in answer, got {len(lines)}\", file=sys.stderr)\n        return None\n\n    for line in lines:\n        if \"|\" in line:\n            key, value = line.split(\"|\", 1)\n            result[key.strip()] = value.strip()\n\n    return result\n\ndef load_expected_answer(label_path):\n    \"\"\"\n    Load the expected answer from label.txt file.\n    Returns a dictionary with the expected values.\n    \"\"\"\n    try:\n        with open(label_path, \"r\") as f:\n            content = f.read().strip()\n\n        # Parse the answer from the label file\n        # The label file contains <answer>...</answer> tags\n        match = re.search(r\"<answer>(.*?)</answer>\", content, re.IGNORECASE | re.DOTALL)\n        if match:\n            answer_content = match.group(1).strip()\n            lines = answer_content.split(\"\\n\")\n        else:\n            # Fallback: treat the whole file as answer content\n            lines = content.split(\"\\n\")\n\n        expected = {}\n        for line in lines:\n            if \"|\" in line:\n                key, value = line.split(\"|\", 1)\n                expected[key.strip()] = value.strip()\n\n        return expected\n    except Exception as e:\n        print(f\"Error reading label file: {str(e)}\", file=sys.stderr)\n        return None\n\ndef compare_answers(model_answer, expected_answer):\n    \"\"\"\n    Compare the model's answer with the expected answer.\n    Returns True if all key information matches, False otherwise.\n    \"\"\"\n    if not model_answer or not expected_answer:\n        return False\n\n    # Check each expected key\n    mismatches = []\n    for key, expected_value in expected_answer.items():\n        model_value = model_answer.get(key, \"\")\n\n        # Special handling for different types of values\n        if key in [\"Battery1Price\", \"Battery2Price\", \"InitialSubtotal\", \"FinalSubtotal\"]:\n            # For price fields, only support $XX.XX format\n            # Check if model value has correct format\n            if not model_value.startswith(\"$\"):\n                mismatches.append(\n                    f\"{key}: incorrect format - expected '$XX.XX' format, got '{model_value}'\"\n                )\n            else:\n                # Normalize and compare values\n                expected_clean = expected_value.replace(\"$\", \"\").replace(\",\", \"\")\n                model_clean = model_value.replace(\"$\", \"\").replace(\",\", \"\")\n                if expected_clean != model_clean:\n                    mismatches.append(\n                        f\"{key}: expected '{expected_value}', got '{model_value}'\"\n                    )\n\n        else:\n            # Exact match for other fields\n            if model_value != expected_value:\n                mismatches.append(\n                    f\"{key}: expected '{expected_value}', got '{model_value}'\"\n                )\n\n    if mismatches:\n        print(\"\\n=== Answer Comparison Mismatches ===\", file=sys.stderr)\n        for mismatch in mismatches:\n            print(f\"✗ {mismatch}\", file=sys.stderr)\n        return False\n\n    print(\"\\n=== Answer Comparison ===\", file=sys.stderr)\n    print(\"✓ All key information matches the expected answer\", file=sys.stderr)\n    return True\n\nasync def verify() -> bool:\n    \"\"\"\n    Verifies that the health routine optimization task has been completed correctly.\n    Checks the model's answer against the expected label.\n    \"\"\"\n    # Get the label file path\n    label_path = Path(__file__).parent / \"label.txt\"\n\n    # Load expected answer\n    expected_answer = load_expected_answer(label_path)\n    if not expected_answer:\n        print(\"Error: Could not load expected answer from label.txt\", file=sys.stderr)\n        return False\n\n    # Get model's response from MCP_MESSAGES\n    model_response = get_model_response()\n    if model_response:\n        print(\"Found model response, parsing answer format...\", file=sys.stderr)\n        model_answer = parse_answer_format(model_response)\n\n        if model_answer:\n            print(\"\\n=== Model Answer Parsed ===\", file=sys.stderr)\n            for key, value in model_answer.items():\n                print(f\"{key}: {value}\", file=sys.stderr)\n\n            # Compare answers\n            answer_match = compare_answers(model_answer, expected_answer)\n            if not answer_match:\n                print(\"\\nModel answer does not match expected answer\", file=sys.stderr)\n                return False\n            print(\"\\n✓ Model answer matches expected answer\", file=sys.stderr)\n            return True\n        else:\n            print(\n                \"Warning: Could not parse answer format from model response\",\n                file=sys.stderr,\n            )\n            return False\n    else:\n        print(\"No model response found\", file=sys.stderr)\n        return False\n\n\ndef main():\n    \"\"\"\n    Executes the verification process and exits with a status code.\n    \"\"\"\n    result = asyncio.run(verify())\n    sys.exit(0 if result else 1)\n\n\nif __name__ == \"__main__\":\n    main()"
}