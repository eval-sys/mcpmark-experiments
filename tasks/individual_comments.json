{
  "task_id": "individual_comments",
  "task_name": "Individual Comments",
  "category_id": "legal_document",
  "category_name": "Legal Document",
  "description": "Extract and analyze individual reviewer comments on legal clauses across multiple document versions to understand personal perspectives.",
  "author": "Lingjun Chen",
  "created_at": "2025-08-15",
  "difficulty": "L3",
  "tags": [
    "data extraction",
    "cross-referencing",
    "pattern analysis"
  ],
  "mcp": [
    "filesystem"
  ],
  "metadata": {},
  "instruction": "# Legal Document Dispute Review Task\n\n**Overview**\n\nThe folder \"legal_files/\" contains all versions (Preferred_Stock_Purchase_Agreement_v0.txt  -- Preferred_Stock_Purchase_Agreement_v10.txt) of the Stock Purchase Agreement for a corporate investment project.\n\nThere are comments in it, come from four people:\n\n- **Bill Harvey** (Company CEO)\n- **Michelle Jackson** (Investor)\n- **David Russel** (Company Counsel)\n- **Tony Taylor** (Investor Counsel)\n\nBetween v1 and v9, these four people make comments on the clauses. The comment format is `[name:content]`, where:\n\n- `name` is the commenter's name\n- `content` is the revision note\n\n**Special Note:** If the name is \"All parties\", it represents a joint comment from all parties, which counts as one comment but does not count toward any individual's personal comment count.\n\n## Task\n\nYour task is to count the number of comments made by Bill Harvey (Company CEO), Michelle Jackson (Investor), David Russel (Company Counsel), and Tony Taylor (Investor Counsel) in clauses 1.1, 1.3, 4.6, 4.16, 6.8, and 6.16 **in version 5-8.** Please generate `individual_comment.csv` in the **main directory** where the first row contains these clauses (1.1, 1.3, 4.6, 4.16, 6.8, 6.16) and the first column contains the four names (Bill Harvey, Michelle Jackson, David Russel, Tony Taylor). Fill in the table with the number of comments for each person and each clause. If there are no comments, write 0.\n",
  "verify": "#!/usr/bin/env python3\n\"\"\"\nVerification script for Legal Document Individual Comments Task\n\"\"\"\n\nimport sys\nfrom pathlib import Path\nimport csv\nimport os\n\ndef get_test_directory() -> Path:\n    \"\"\"Get the test directory from FILESYSTEM_TEST_DIR env var.\"\"\"\n    test_root = os.environ.get(\"FILESYSTEM_TEST_DIR\")\n    if not test_root:\n        raise ValueError(\"FILESYSTEM_TEST_DIR environment variable is required\")\n    return Path(test_root)\n\ndef verify_output_file_exists(test_dir: Path) -> bool:\n    \"\"\"Verify that the individual_comment.csv file exists.\"\"\"\n    output_file = test_dir / \"individual_comment.csv\"\n    \n    if not output_file.exists():\n        print(\"❌ File 'individual_comment.csv' not found\")\n        return False\n    \n    print(\"✅ Output file 'individual_comment.csv' found\")\n    return True\n\ndef verify_csv_format(test_dir: Path) -> bool:\n    \"\"\"Verify that the CSV file has the correct format.\"\"\"\n    output_file = test_dir / \"individual_comment.csv\"\n    \n    try:\n        with open(output_file, 'r', newline='', encoding='utf-8') as csvfile:\n            reader = csv.reader(csvfile)\n            rows = list(reader)\n            \n            if not rows:\n                print(\"❌ CSV file is empty\")\n                return False\n            \n            # Check if there are at least 2 rows (header + data)\n            if len(rows) < 2:\n                print(\"❌ CSV file has insufficient rows\")\n                return False\n            \n            # Check if header row has correct number of columns\n            header = rows[0]\n            if len(header) != 7:  # First column (can be anything) + 6 clauses\n                print(f\"❌ Header row has incorrect number of columns: {len(header)}, expected 7\")\n                return False\n            \n            # Check if data rows have correct number of columns\n            for i, row in enumerate(rows[1:], 1):\n                if len(row) != 7:\n                    print(f\"❌ Data row {i} has incorrect number of columns: {len(row)}, expected 7\")\n                    return False\n            \n            print(\"✅ CSV format is correct\")\n            return True\n            \n    except Exception as e:\n        print(f\"❌ Error reading CSV file: {e}\")\n        return False\n\ndef verify_csv_content(test_dir: Path) -> bool:\n    \"\"\"Verify that the CSV content matches the expected answer exactly.\"\"\"\n    output_file = test_dir / \"individual_comment.csv\"\n    \n    try:\n        with open(output_file, 'r', newline='', encoding='utf-8') as csvfile:\n            reader = csv.reader(csvfile)\n            rows = list(reader)\n            \n            # Expected data based on answer.csv\n            expected_data = {\n                \"Bill Harvey\": [\"0\", \"2\", \"3\", \"1\", \"1\", \"1\"],\n                \"Michelle Jackson\": [\"0\", \"1\", \"2\", \"1\", \"1\", \"1\"],\n                \"David Russel\": [\"2\", \"1\", \"1\", \"2\", \"1\", \"1\"],\n                \"Tony Taylor\": [\"2\", \"0\", \"1\", \"2\", \"1\", \"1\"]\n            }\n            \n            # Expected header columns (excluding first column which can be anything)\n            expected_header_columns = [\"1.1\", \"1.3\", \"4.6\", \"4.16\", \"6.8\", \"6.16\"]\n            \n            # Verify header has correct number of columns\n            header = rows[0]\n            if len(header) != 7:  # First column + 6 clauses\n                print(f\"❌ Header row has incorrect number of columns: {len(header)}, expected 7\")\n                return False\n            \n            # Check if all expected clause columns are present (allow order to be different)\n            # Allow first column to be anything, so we check columns 1-6\n            header_clauses = header[1:7]\n            missing_clauses = []\n            for expected_clause in expected_header_columns:\n                if expected_clause not in header_clauses:\n                    missing_clauses.append(expected_clause)\n            \n            if missing_clauses:\n                print(f\"❌ Missing expected clause columns: {missing_clauses}\")\n                return False\n            \n            # Check if there are extra clause columns\n            extra_clauses = []\n            for clause in header_clauses:\n                if clause not in expected_header_columns:\n                    extra_clauses.append(clause)\n            \n            if extra_clauses:\n                print(f\"❌ Unexpected extra clause columns: {extra_clauses}\")\n                return False\n            \n            # Create a mapping from expected clause order to actual column indices\n            clause_mapping = {}\n            for i, clause in enumerate(header_clauses):\n                if clause in expected_header_columns:\n                    clause_mapping[clause] = i\n            \n            # Parse the CSV data into a dictionary with correct column mapping\n            csv_data = {}\n            for row in rows[1:]:\n                if len(row) >= 7:\n                    name = row[0]\n                    # Map values according to the expected clause order\n                    values = []\n                    for expected_clause in expected_header_columns:\n                        col_index = clause_mapping[expected_clause] + 1  # +1 because we skip first column\n                        values.append(row[col_index])\n                    csv_data[name] = values\n            \n            # Check if all expected names are present\n            missing_names = []\n            for expected_name in expected_data:\n                if expected_name not in csv_data:\n                    missing_names.append(expected_name)\n            \n            if missing_names:\n                print(f\"❌ Missing expected names: {missing_names}\")\n                return False\n            \n            # Check if there are extra names\n            extra_names = []\n            for name in csv_data:\n                if name not in expected_data:\n                    extra_names.append(name)\n            \n            if extra_names:\n                print(f\"❌ Unexpected extra names: {extra_names}\")\n                return False\n            \n            # Check values for each person\n            for name, expected_values in expected_data.items():\n                actual_values = csv_data[name]\n                \n                if actual_values != expected_values:\n                    print(f\"❌ Values mismatch for {name}:\")\n                    print(f\"   Expected: {expected_values}\")\n                    print(f\"   Got:      {actual_values}\")\n                    return False\n            \n            print(\"✅ CSV content matches expected answer exactly\")\n            return True\n            \n    except Exception as e:\n        print(f\"❌ Error verifying CSV content: {e}\")\n        return False\n\ndef verify_data_accuracy(test_dir: Path) -> bool:\n    \"\"\"Verify that the data values are accurate (all values are non-negative integers).\"\"\"\n    output_file = test_dir / \"individual_comment.csv\"\n    \n    try:\n        with open(output_file, 'r', newline='', encoding='utf-8') as csvfile:\n            reader = csv.reader(csvfile)\n            rows = list(reader)\n            \n            # Skip header row\n            for i, row in enumerate(rows[1:], 1):\n                if len(row) >= 7:\n                    name = row[0]\n                    values = row[1:7]\n                    \n                    for j, value in enumerate(values, 1):\n                        try:\n                            int_val = int(value)\n                            if int_val < 0:\n                                print(f\"❌ Row {i}, column {j}: negative value '{value}' for {name}\")\n                                return False\n                        except ValueError:\n                            print(f\"❌ Row {i}, column {j}: non-integer value '{value}' for {name}\")\n                            return False\n            \n            print(\"✅ All data values are valid non-negative integers\")\n            return True\n            \n    except Exception as e:\n        print(f\"❌ Error verifying data accuracy: {e}\")\n        return False\n\ndef verify_file_location(test_dir: Path) -> bool:\n    \"\"\"Verify that the file is in the main directory (not in a subdirectory).\"\"\"\n    output_file = test_dir / \"individual_comment.csv\"\n    \n    if output_file.exists():\n        print(\"✅ File is located in the main directory\")\n        return True\n    else:\n        print(\"❌ File is not in the main directory\")\n        return False\n\ndef main():\n    \"\"\"Main verification function.\"\"\"\n    test_dir = get_test_directory()\n    print(\"🔍 Verifying Legal Document Individual Comments Task...\")\n    \n    # Define verification steps\n    verification_steps = [\n        (\"Output File Exists\", verify_output_file_exists),\n        (\"CSV Format\", verify_csv_format),\n        (\"CSV Content\", verify_csv_content),\n        (\"Data Accuracy\", verify_data_accuracy),\n        (\"File Location\", verify_file_location),\n    ]\n    \n    # Run all verification steps\n    all_passed = True\n    for step_name, verify_func in verification_steps:\n        print(f\"\\n--- {step_name} ---\")\n        if not verify_func(test_dir):\n            all_passed = False\n    \n    # Final result\n    print(\"\\n\" + \"=\"*50)\n    if all_passed:\n        print(\"✅ Legal document individual comments task completed correctly!\")\n        print(\"🎉 Task verification: PASS\")\n        sys.exit(0)\n    else:\n        print(\"❌ Task verification: FAIL\")\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()"
}