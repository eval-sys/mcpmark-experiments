{
  "task_id": "author_folders",
  "task_name": "Author Folders",
  "category_id": "papers",
  "category_name": "Papers",
  "description": "Analyze academic papers to identify and organize by author, creating separate folders for frequent authors (‚â•4 papers) and prolific 2025 authors (‚â•3 papers).",
  "author": "Xiangyan Liu",
  "created_at": "2025-08-12",
  "difficulty": "L3",
  "tags": [
    "data extraction",
    "file organization",
    "pattern analysis"
  ],
  "mcp": [
    "filesystem"
  ],
  "metadata": {},
  "instruction": "# Paper Organization Task: Author-Based Paper Categorization\n\n## üìã Task Description\n\nYou are given a directory containing multiple paper files. You have a collection of academic papers in HTML format from arXiv. Your task is to analyze these papers, identify authors who have published multiple papers, and organize them into author-specific folders based on specified criteria.\n\n## üéØ Task Objectives\n\n### Part 1: Frequent Authors (‚â•4 papers)\n1. **Extract author information** from all HTML papers in the given directory\n2. **Identify authors** who appear in 4 or more papers\n3. **Create a directory** `frequent_authors` \n4. **Create individual folders** within this directory for each frequent author (lowercase names with underscores)\n5. **Copy their papers** to their respective folders\n\n### Part 2: Prolific 2025 Authors (‚â•3 papers)\n1. **Extract publication dates** along with author information\n2. **Identify authors** who published 3 or more papers in 2025\n3. **Create a directory** `2025_authors` for 2025 authors\n4. **Create individual folders** within this directory for each prolific 2025 author (lowercase names with underscores)\n5. **Copy their 2025 papers** to their respective folders\n\n## üìù Expected Output\n\n### Directory Structure:\n```\n[given_task_folder]/\n‚îú‚îÄ‚îÄ [original HTML files remain untouched]\n‚îú‚îÄ‚îÄ frequent_authors/              # Authors with ‚â•4 papers total\n‚îÇ   ‚îú‚îÄ‚îÄ smith_john/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [copied papers]\n‚îÇ   ‚îú‚îÄ‚îÄ johnson_sarah/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [copied papers]\n‚îÇ   ‚îî‚îÄ‚îÄ ...\n‚îî‚îÄ‚îÄ 2025_authors/                  # Authors with ‚â•3 papers in 2025\n    ‚îú‚îÄ‚îÄ williams_david/\n    ‚îÇ   ‚îî‚îÄ‚îÄ [copied 2025 papers]\n    ‚îú‚îÄ‚îÄ brown_emily/\n    ‚îÇ   ‚îî‚îÄ‚îÄ [copied 2025 papers]\n    ‚îî‚îÄ‚îÄ ...\n```\n\n### Requirements:\n- Author folder names should be **lowercase** with underscores replacing spaces/commas (e.g., `smith_john`, `williams_david`)\n- Papers should be **copied** (not moved) to preserve originals\n- Author extraction should handle various name formats correctly",
  "verify": "#!/usr/bin/env python3\n\"\"\"\nVerification script for Paper Organization Task: Author-Based Paper Categorization\n\"\"\"\n\nimport sys\nfrom pathlib import Path\nimport os\nimport re\nfrom typing import Dict, List, Set\nfrom html.parser import HTMLParser\nfrom datetime import datetime\n\ndef get_test_directory() -> Path:\n    \"\"\"Get the test directory from FILESYSTEM_TEST_DIR env var.\"\"\"\n    test_root = os.environ.get(\"FILESYSTEM_TEST_DIR\")\n    if not test_root:\n        raise ValueError(\"FILESYSTEM_TEST_DIR environment variable is required\")\n    return Path(test_root)\n\nclass ArxivHTMLParser(HTMLParser):\n    \"\"\"Parser to extract author and date information from arXiv HTML papers.\"\"\"\n    \n    def __init__(self):\n        super().__init__()\n        self.authors = []\n        self.publication_date = None\n        \n    def handle_starttag(self, tag, attrs):\n        # Look for author metadata tags\n        if tag == 'meta':\n            attr_dict = dict(attrs)\n            if attr_dict.get('name') == 'citation_author':\n                content = attr_dict.get('content', '')\n                if content:\n                    self.authors.append(content)\n            elif attr_dict.get('name') in ['citation_date', 'citation_online_date']:\n                content = attr_dict.get('content', '')\n                if content and not self.publication_date:\n                    self.publication_date = content\n\ndef extract_paper_info(html_file: Path) -> tuple[List[str], str]:\n    \"\"\"Extract authors and publication year from an HTML paper.\"\"\"\n    try:\n        with open(html_file, 'r', encoding='utf-8', errors='ignore') as f:\n            content = f.read()\n            \n        parser = ArxivHTMLParser()\n        parser.feed(content)\n        \n        # Extract year from date if available\n        year = None\n        if parser.publication_date:\n            # Parse year from date string (e.g., \"2025/03/13\")\n            year_match = re.search(r'(\\d{4})', parser.publication_date)\n            if year_match:\n                year = year_match.group(1)\n        \n        return parser.authors, year\n        \n    except Exception as e:\n        print(f\"Warning: Could not parse {html_file.name}: {e}\")\n        return [], None\n\ndef normalize_author_name(author: str) -> str:\n    \"\"\"Normalize author name to lowercase with underscores.\"\"\"\n    # Author names are in \"Last, First Middle\" format\n    # We need to convert to \"first_last\" format\n    \n    # Remove any HTML entities or special characters that shouldn't be there\n    author = author.strip()\n    \n    # Split by comma to separate last and first names\n    parts = author.split(',', 1)\n    if len(parts) == 2:\n        last_name = parts[0].strip()\n        first_names = parts[1].strip()\n        # Take only the first name (not middle names)\n        first_name_parts = first_names.split()\n        if first_name_parts:\n            first_name = first_name_parts[0]\n            # Format as \"first_last\"\n            normalized = f\"{first_name}_{last_name}\"\n        else:\n            normalized = last_name\n    else:\n        # If no comma, use as is\n        normalized = author\n    \n    # Convert to lowercase and replace spaces/special chars with underscores\n    normalized = re.sub(r'[^\\w\\s-]', '', normalized)\n    normalized = re.sub(r'[\\s-]+', '_', normalized)\n    return normalized.lower()\n\ndef verify_directories_exist(test_dir: Path) -> bool:\n    \"\"\"Verify that required directories exist.\"\"\"\n    frequent_authors_dir = test_dir / \"frequent_authors\"\n    authors_2025_dir = test_dir / \"2025_authors\"\n    \n    if not frequent_authors_dir.exists():\n        print(\"‚ùå 'frequent_authors' directory not found\")\n        return False\n    \n    if not authors_2025_dir.exists():\n        print(\"‚ùå '2025_authors' directory not found\")\n        return False\n    \n    if not frequent_authors_dir.is_dir():\n        print(\"‚ùå 'frequent_authors' exists but is not a directory\")\n        return False\n        \n    if not authors_2025_dir.is_dir():\n        print(\"‚ùå '2025_authors' exists but is not a directory\")\n        return False\n    \n    print(\"‚úÖ Both required directories exist\")\n    return True\n\ndef analyze_papers(test_dir: Path) -> tuple[Dict[str, List[Path]], Dict[str, List[Path]]]:\n    \"\"\"Analyze all HTML papers and return author-paper mappings.\"\"\"\n    author_papers = {}  # author -> list of papers\n    author_2025_papers = {}  # author -> list of 2025 papers\n    \n    # Find all HTML files\n    html_files = list(test_dir.glob(\"*.html\"))\n    \n    for html_file in html_files:\n        authors, year = extract_paper_info(html_file)\n        \n        for author in authors:\n            if not author:\n                continue\n                \n            normalized_name = normalize_author_name(author)\n            if not normalized_name:\n                continue\n            \n            # Track all papers by author\n            if normalized_name not in author_papers:\n                author_papers[normalized_name] = []\n            author_papers[normalized_name].append(html_file)\n            \n            # Track 2025 papers\n            if year == '2025':\n                if normalized_name not in author_2025_papers:\n                    author_2025_papers[normalized_name] = []\n                author_2025_papers[normalized_name].append(html_file)\n    \n    return author_papers, author_2025_papers\n\ndef verify_frequent_authors(test_dir: Path, author_papers: Dict[str, List[Path]]) -> bool:\n    \"\"\"Verify that authors with ‚â•4 papers have their folders and papers.\"\"\"\n    frequent_authors_dir = test_dir / \"frequent_authors\"\n    \n    # Find authors with 4 or more papers\n    frequent_authors = {author: papers for author, papers in author_papers.items() \n                        if len(papers) >= 4}\n    \n    if not frequent_authors:\n        print(\"‚ö†Ô∏è  No authors found with 4 or more papers\")\n        # This might be expected depending on the test data\n        return True\n    \n    all_correct = True\n    \n    for author, expected_papers in frequent_authors.items():\n        author_dir = frequent_authors_dir / author\n        \n        # Check if author directory exists\n        if not author_dir.exists():\n            print(f\"‚ùå Missing directory for frequent author: {author}\")\n            all_correct = False\n            continue\n        \n        # Check if all expected papers are present\n        for paper in expected_papers:\n            paper_copy = author_dir / paper.name\n            if not paper_copy.exists():\n                print(f\"‚ùå Missing paper {paper.name} in {author} directory\")\n                all_correct = False\n    \n    # Check for unexpected directories\n    for item in frequent_authors_dir.iterdir():\n        if item.is_dir():\n            dir_name = item.name\n            if dir_name not in frequent_authors:\n                # Check if this author has less than 4 papers\n                if dir_name in author_papers and len(author_papers[dir_name]) < 4:\n                    print(f\"‚ùå Author {dir_name} has only {len(author_papers[dir_name])} papers but has a folder in frequent_authors\")\n                    all_correct = False\n    \n    if all_correct:\n        print(f\"‚úÖ Frequent authors correctly organized ({len(frequent_authors)} authors)\")\n    \n    return all_correct\n\ndef verify_2025_authors(test_dir: Path, author_2025_papers: Dict[str, List[Path]]) -> bool:\n    \"\"\"Verify that authors with ‚â•3 papers in 2025 have their folders and papers.\"\"\"\n    authors_2025_dir = test_dir / \"2025_authors\"\n    \n    # Find authors with 3 or more papers in 2025\n    prolific_2025_authors = {author: papers for author, papers in author_2025_papers.items() \n                             if len(papers) >= 3}\n    \n    if not prolific_2025_authors:\n        print(\"‚ö†Ô∏è  No authors found with 3 or more papers in 2025\")\n        # This might be expected depending on the test data\n        return True\n    \n    all_correct = True\n    \n    for author, expected_papers in prolific_2025_authors.items():\n        author_dir = authors_2025_dir / author\n        \n        # Check if author directory exists\n        if not author_dir.exists():\n            print(f\"‚ùå Missing directory for 2025 author: {author}\")\n            all_correct = False\n            continue\n        \n        # Check if all expected 2025 papers are present\n        for paper in expected_papers:\n            paper_copy = author_dir / paper.name\n            if not paper_copy.exists():\n                print(f\"‚ùå Missing 2025 paper {paper.name} in {author} directory\")\n                all_correct = False\n    \n    # Check for unexpected directories\n    for item in authors_2025_dir.iterdir():\n        if item.is_dir():\n            dir_name = item.name\n            if dir_name not in prolific_2025_authors:\n                # Check if this author has less than 3 papers in 2025\n                if dir_name in author_2025_papers and len(author_2025_papers[dir_name]) < 3:\n                    print(f\"‚ùå Author {dir_name} has only {len(author_2025_papers[dir_name])} papers in 2025 but has a folder in 2025_authors\")\n                    all_correct = False\n    \n    if all_correct:\n        print(f\"‚úÖ 2025 authors correctly organized ({len(prolific_2025_authors)} authors)\")\n    \n    return all_correct\n\ndef verify_original_files_intact(test_dir: Path) -> bool:\n    \"\"\"Verify that original HTML files are still present (not moved).\"\"\"\n    html_files = list(test_dir.glob(\"*.html\"))\n    \n    if not html_files:\n        print(\"‚ùå No original HTML files found in root directory\")\n        return False\n    \n    print(f\"‚úÖ Original HTML files remain intact ({len(html_files)} files)\")\n    return True\n\ndef verify_naming_convention(test_dir: Path) -> bool:\n    \"\"\"Verify that author folder names follow the correct naming convention.\"\"\"\n    frequent_authors_dir = test_dir / \"frequent_authors\"\n    authors_2025_dir = test_dir / \"2025_authors\"\n    \n    all_correct = True\n    \n    # Check frequent_authors subdirectories\n    for author_dir in frequent_authors_dir.iterdir():\n        if author_dir.is_dir():\n            name = author_dir.name\n            # Check for lowercase and underscores only\n            if not re.match(r'^[a-z0-9_]+$', name):\n                print(f\"‚ùå Invalid folder name in frequent_authors: {name} (should be lowercase with underscores)\")\n                all_correct = False\n    \n    # Check 2025_authors subdirectories\n    for author_dir in authors_2025_dir.iterdir():\n        if author_dir.is_dir():\n            name = author_dir.name\n            # Check for lowercase and underscores only\n            if not re.match(r'^[a-z0-9_]+$', name):\n                print(f\"‚ùå Invalid folder name in 2025_authors: {name} (should be lowercase with underscores)\")\n                all_correct = False\n    \n    if all_correct:\n        print(\"‚úÖ All author folder names follow correct naming convention\")\n    \n    return all_correct\n\ndef main():\n    \"\"\"Main verification function.\"\"\"\n    try:\n        test_dir = get_test_directory()\n        print(f\"üîç Verifying paper organization in: {test_dir}\")\n        \n        # Analyze papers first\n        print(\"\\nüìä Analyzing papers...\")\n        author_papers, author_2025_papers = analyze_papers(test_dir)\n        \n        # Run verification checks\n        checks = [\n            (\"Directory existence\", lambda: verify_directories_exist(test_dir)),\n            (\"Original files intact\", lambda: verify_original_files_intact(test_dir)),\n            (\"Frequent authors organization\", lambda: verify_frequent_authors(test_dir, author_papers)),\n            (\"2025 authors organization\", lambda: verify_2025_authors(test_dir, author_2025_papers)),\n            (\"Naming conventions\", lambda: verify_naming_convention(test_dir))\n        ]\n        \n        all_passed = True\n        for check_name, check_func in checks:\n            print(f\"\\nüìã Checking: {check_name}\")\n            if not check_func():\n                all_passed = False\n        \n        if all_passed:\n            print(\"\\nüéâ All verification checks passed!\")\n            sys.exit(0)\n        else:\n            print(\"\\n‚ùå Some verification checks failed!\")\n            sys.exit(1)\n            \n    except Exception as e:\n        print(f\"‚ùå Verification failed with error: {e}\")\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()",
  "model_results": {
    "gemini-2-5-pro": 0,
    "deepseek-chat": 0,
    "qwen-3-coder": 0,
    "o3": 0,
    "gpt-5": 0,
    "k2": 0,
    "claude-4-sonnet": 0
  }
}