{
  "task_id": "issue_management_workflow",
  "task_name": "Issue Management Workflow",
  "category_id": "mcpmark-cicd",
  "category_name": "MCPMark CI/CD",
  "description": "Build intelligent issue management automation with auto-triage, task breakdown for epics, and first-time contributor handling.",
  "author": "Zijian Wu",
  "created_at": "2025-08-15",
  "difficulty": "L3",
  "tags": [
    "issue management",
    "workflow automation"
  ],
  "mcp": [
    "github"
  ],
  "meta_data": {
    "stateType": "url",
    "stateContent": null,
    "stateUrl": "https://github.com/mcpmark-source/mcpmark-cicd",
    "stateOriginalUrl": null
  },
  "instruction": "I need you to create an intelligent Issue Management automation workflow for this Node.js project. The project currently has no GitHub Actions workflows, so you'll be building an issue-focused automation system from scratch that responds to issue events. Here's what needs to be implemented:\n\n## Issue Management Workflow\n\nCreate `.github/workflows/issue-automation.yml` that triggers on `issues` events (opened, labeled) with these jobs:\n\n### 1. **issue-triage** job:\n   - Auto-assigns category labels based on keywords in **issue title** (case-insensitive):\n     - Title contains \"bug\" ‚Üí adds `bug` label\n     - Title contains \"epic\" ‚Üí adds `epic` label  \n     - Title contains \"maintenance\" ‚Üí adds `maintenance` label\n   - Auto-assigns priority labels based on keywords in **issue title OR body** (case-insensitive, highest priority wins if multiple keywords found):\n     - \"critical\", \"urgent\", \"production\", \"outage\" ‚Üí `priority-critical`\n     - \"important\", \"high\", \"blocking\" ‚Üí `priority-high` \n     - \"medium\", \"normal\" ‚Üí `priority-medium` (default if no priority keywords found)\n     - \"low\", \"nice-to-have\", \"minor\" ‚Üí `priority-low`\n   - All issues get `needs-triage` label initially\n\n### 2. **task-breakdown** job:\n   - For issues with a title containing \"Epic\", create exactly 4 sub-issues with the pattern: \"[SUBTASK] [Original Title] - Task N: [Task Name]\"\n   - Task names: 1. Requirements Analysis, 2. Design and Architecture, 3. Implementation, 4. Testing and Documentation\n   - Links sub-issues to parent using \"Related to #[parent-number]\" in sub-issue body\n   - Updates parent issue body with \"## Epic Tasks\" checklist linking to sub-issue numbers\n   - All sub-issues get `enhancement` and `needs-review` labels\n\n### 3. **auto-response** job:\n   - Checks if the issue author is creating their first issue in this repository (not first on GitHub globally, but first in this specific repo)\n   - If first issue in repo: adds `first-time-contributor` label and posts welcome message\n   - Posts different responses based on issue type:\n     - `bug` issues: comment must contain \"Bug Report Guidelines\"\n     - `epic` issues: comment must contain \"Feature Request Process\"  \n     - `maintenance` issues: comment must contain \"Maintenance Guidelines\"\n   - Sets milestone \"v1.0.0\" for `priority-high` and `priority-critical` issues\n   - Changes status from `needs-triage` to `needs-review` after response\n\n## Label Management Requirements\n\nThe system must create and manage these specific labels:\n\n### Category Labels:\n- `bug` - Something isn't working\n- `enhancement` - New feature or request  \n- `epic` - Large feature requiring multiple sub-tasks\n- `maintenance` - Maintenance and housekeeping tasks\n\n### Priority Labels:\n- `priority-critical` - Critical priority issue\n- `priority-high` - High priority issue  \n- `priority-medium` - Medium priority issue\n- `priority-low` - Low priority issue\n\n### Status Labels:\n- `needs-triage` - Needs to be reviewed by maintainers\n- `needs-review` - Awaiting review from maintainers\n- `first-time-contributor` - Issue created by first-time contributor\n\n## Implementation Requirements:\n\n**Step 1: Create Feature Branch**\nCreate a new branch called `issue-management-workflow` from main.\n\n**Step 2: Create Supporting Files**\nCreate these additional files on the new branch:\n- `.github/ISSUE_TEMPLATE/bug_report.md` - Bug report template\n- `.github/ISSUE_TEMPLATE/feature_request.md` - Feature request template\n- `.github/ISSUE_TEMPLATE/maintenance_report.md` - Maintenance report template\n\n\n**Step 3: Implement the Workflow**  \nCreate `.github/workflows/issue-automation.yml` with proper YAML syntax.  \nInclude:  \n- Appropriate triggers for issues events  \n- Job dependencies where needed  \n- Error handling and graceful fallbacks  \n- Avoid identifier conflicts in github-script actions (don't redeclare 'github')\n\n**Step 4: Create and Merge Pull Request**\nCreate a comprehensive pull request and merge it to main:\n- Title: \"Implement Issue Management Automation Workflow\"\n- Detailed description of the workflow and its purpose\n- Include all workflow files and templates created\n- Merge the pull request to main branch\n\n**Step 5: Test the Workflow**\nCreate test issues to demonstrate the issue automation workflow:\n\n1. **Bug Issue**: \"Bug: Login form validation not working\"\n   - Expected: `bug`, `priority-high`, `needs-triage`‚Üí`needs-review`, milestone \"v1.0.0\"\n   - Auto-response comment must contain \"Bug Report Guidelines\"\n\n2. **Epic Issue**: \"Epic: Redesign user dashboard interface\"\n   - Expected: `epic`, `priority-high`, `needs-triage`‚Üí`needs-review`, milestone \"v1.0.0\"\n   - Must create 4 sub-issues with `enhancement` and `needs-review` labels\n   - Parent updated with \"## Epic Tasks\" checklist, sub-issues linked with \"Related to #[parent-number]\"\n   - Auto-response comment must contain \"Feature Request Process\"\n\n3. **Maintenance Issue**: \"Weekly maintenance cleanup and refactor\"  \n   - Expected: `maintenance`, `priority-medium`, `needs-triage`‚Üí`needs-review`, no milestone\n   - Auto-response comment must contain \"Maintenance Guidelines\"",
  "verify": "import sys\nimport os\nimport requests\nimport time\nfrom typing import Dict, List, Optional, Tuple\nfrom dotenv import load_dotenv\n\n\ndef _get_github_api(\n    endpoint: str, headers: Dict[str, str], owner: str, repo: str\n) -> Tuple[bool, Optional[Dict]]:\n    \"\"\"Make a GET request to GitHub API and return (success, response).\"\"\"\n    url = f\"https://api.github.com/repos/{owner}/{repo}/{endpoint}\"\n    try:\n        response = requests.get(url, headers=headers)\n        if response.status_code == 200:\n            return True, response.json()\n        elif response.status_code == 404:\n            return False, None\n        else:\n            print(f\"API error for {endpoint}: {response.status_code}\", file=sys.stderr)\n            return False, None\n    except Exception as e:\n        print(f\"Exception for {endpoint}: {e}\", file=sys.stderr)\n        return False, None\n\n\ndef _search_github_issues(\n    query: str, headers: Dict[str, str]\n) -> Tuple[bool, Optional[List]]:\n    \"\"\"Search GitHub issues using the search API.\"\"\"\n    url = f\"https://api.github.com/search/issues?q={query}&per_page=100\"\n    try:\n        response = requests.get(url, headers=headers)\n        if response.status_code == 200:\n            data = response.json()\n            return True, data.get(\"items\", [])\n        else:\n            print(f\"Search API error: {response.status_code}\", file=sys.stderr)\n            return False, None\n    except Exception as e:\n        print(f\"Search exception: {e}\", file=sys.stderr)\n        return False, None\n\n\ndef _wait_for_workflow_completion(\n    headers: Dict[str, str], owner: str, repo: str, max_wait: int = 180\n) -> bool:\n    \"\"\"Wait for GitHub Actions workflows to complete processing.\"\"\"\n    print(\"‚è≥ Waiting for GitHub Actions workflows to complete...\")\n\n    start_time = time.time()\n    expected_runs = 3  # We created 3 test issues\n    no_workflow_check_count = 0\n\n    while time.time() - start_time < max_wait:\n        try:\n            # Check workflow runs\n            success, response = _get_github_api(\n                \"actions/workflows/issue-automation.yml/runs?per_page=20\",\n                headers,\n                owner,\n                repo,\n            )\n\n            if success and response:\n                runs = response.get(\"workflow_runs\", [])\n                if len(runs) >= expected_runs:\n                    # Check status of recent runs\n                    recent_runs = runs[:expected_runs]\n\n                    running_count = 0\n                    completed_count = 0\n                    failed_count = 0\n\n                    for run in recent_runs:\n                        status = run[\"status\"]\n                        conclusion = run.get(\"conclusion\")\n\n                        if status == \"completed\":\n                            completed_count += 1\n                            if conclusion == \"failure\":\n                                failed_count += 1\n                        elif status in [\"in_progress\", \"queued\"]:\n                            running_count += 1\n\n                    print(\n                        f\"   Status: {completed_count} completed, {running_count} running/queued\"\n                    )\n\n                    # Wait until NO workflows are running and we have enough completed runs\n                    if running_count == 0 and completed_count >= expected_runs:\n                        if failed_count > 0:\n                            print(\n                                f\"‚ö†Ô∏è Warning: {failed_count} workflow runs failed, but continuing verification...\"\n                            )\n\n                        print(\n                            f\"‚úÖ All workflows completed. Found {completed_count} completed runs.\"\n                        )\n                        # Additional wait to ensure all issue processing is done\n                        print(\"‚è≥ Additional wait for issue processing to complete...\")\n                        time.sleep(5)\n                        return True\n                elif len(runs) == 0:\n                    # No workflow runs found\n                    no_workflow_check_count += 1\n                    if no_workflow_check_count == 1:\n                        print(\n                            \"   No workflow runs found yet, waiting 5 seconds and checking once more...\"\n                        )\n                        time.sleep(5)\n                        continue\n                    elif no_workflow_check_count >= 2:\n                        print(\n                            \"‚ö†Ô∏è No workflow runs detected after 2 checks. Workflow may not have been triggered.\"\n                        )\n                        print(\"   Continuing with verification...\")\n                        return False\n                else:\n                    print(\n                        f\"   Waiting for workflow runs... Found {len(runs)}, expected {expected_runs}\"\n                    )\n\n            print(f\"‚è≥ Still waiting... ({int(time.time() - start_time)}s elapsed)\")\n            time.sleep(5)\n\n        except Exception as e:\n            print(f\"‚ö†Ô∏è Error checking workflow status: {e}\")\n            time.sleep(5)\n\n    print(f\"‚ö†Ô∏è Workflow completion wait timed out after {max_wait}s\")\n    return False\n\n\ndef _find_issue_by_title(\n    title: str, headers: Dict[str, str], owner: str, repo: str\n) -> Optional[Dict]:\n    \"\"\"Find an issue by exact title match.\"\"\"\n    success, issues = _search_github_issues(\n        f'repo:{owner}/{repo} \"{title}\" is:issue', headers\n    )\n\n    if success and issues:\n        for issue in issues:\n            if issue.get(\"title\") == title:\n                return issue\n    return None\n\n\ndef _check_issue_labels(\n    issue: Dict, expected_labels: List[str]\n) -> Tuple[bool, List[str]]:\n    \"\"\"Check if issue has the expected labels.\"\"\"\n    actual_labels = [label[\"name\"] for label in issue.get(\"labels\", [])]\n    missing_labels = [label for label in expected_labels if label not in actual_labels]\n\n    if missing_labels:\n        return False, [f\"Missing labels: {missing_labels}. Found: {actual_labels}\"]\n    return True, []\n\n\ndef _check_issue_milestone(\n    issue: Dict, expected_milestone: str\n) -> Tuple[bool, List[str]]:\n    \"\"\"Check if issue has the expected milestone.\"\"\"\n    milestone = issue.get(\"milestone\")\n    if not milestone:\n        if expected_milestone:\n            return False, [f\"No milestone found. Expected: {expected_milestone}\"]\n        return True, []\n\n    if milestone.get(\"title\") != expected_milestone:\n        return False, [\n            f\"Wrong milestone: {milestone.get('title')}. Expected: {expected_milestone}\"\n        ]\n\n    return True, []\n\n\ndef _check_issue_comments(\n    issue_number: int,\n    expected_content: str,\n    headers: Dict[str, str],\n    owner: str,\n    repo: str,\n) -> Tuple[bool, List[str]]:\n    \"\"\"Check if issue has a comment containing expected content.\"\"\"\n    success, comments = _get_github_api(\n        f\"issues/{issue_number}/comments\", headers, owner, repo\n    )\n\n    if not success:\n        return False, [\"Failed to get issue comments\"]\n\n    if not comments:\n        return False, [f\"No comments found. Expected comment with: {expected_content}\"]\n\n    for comment in comments:\n        if expected_content in comment.get(\"body\", \"\"):\n            return True, []\n\n    return False, [f\"Expected content '{expected_content}' not found in comments\"]\n\n\ndef _find_epic_sub_issues(\n    parent_issue_number: int, headers: Dict[str, str], owner: str, repo: str\n) -> Tuple[List[Dict], List[str]]:\n    \"\"\"Find sub-issues created for an epic.\"\"\"\n    # Search for each expected sub-task by exact title\n    expected_subtasks = [\n        \"[SUBTASK] Epic: Redesign user dashboard interface - Task 1: Requirements Analysis\",\n        \"[SUBTASK] Epic: Redesign user dashboard interface - Task 2: Design and Architecture\",\n        \"[SUBTASK] Epic: Redesign user dashboard interface - Task 3: Implementation\",\n        \"[SUBTASK] Epic: Redesign user dashboard interface - Task 4: Testing and Documentation\",\n    ]\n\n    subtasks = []\n    errors = []\n\n    for expected_title in expected_subtasks:\n        # Search for exact title\n        success, issues = _search_github_issues(\n            f'repo:{owner}/{repo} \"{expected_title}\" is:issue', headers\n        )\n\n        if not success:\n            errors.append(f\"Failed to search for sub-issue: {expected_title}\")\n            continue\n\n        # Find exact match\n        found = False\n        for issue in issues:\n            if issue.get(\"title\") == expected_title:\n                # Verify it references the parent issue\n                body = issue.get(\"body\", \"\")\n                if (\n                    f\"#{parent_issue_number}\" in body\n                    or f\"Related to #{parent_issue_number}\" in body\n                ):\n                    subtasks.append(issue)\n                    found = True\n                    break\n\n        if not found:\n            errors.append(\n                f\"Sub-issue not found or doesn't reference parent: {expected_title}\"\n            )\n\n    return subtasks, errors\n\n\ndef _check_epic_checklist(\n    issue: Dict, subtask_numbers: List[int]\n) -> Tuple[bool, List[str]]:\n    \"\"\"Check if epic issue has the Epic Tasks checklist with correct issue references.\"\"\"\n    body = issue.get(\"body\", \"\")\n    errors = []\n\n    if \"## Epic Tasks\" not in body:\n        return False, [\"Epic Tasks section not found in issue body\"]\n\n    # Check that all subtask issue numbers are referenced in checkbox format\n    for number in subtask_numbers:\n        # Check for checkbox format: - [ ] #number\n        if f\"- [ ] #{number}\" not in body:\n            errors.append(\n                f\"Sub-issue #{number} not found in Epic Tasks checklist format (expected: '- [ ] #{number}')\"\n            )\n\n    # Also verify the expected task names are present\n    expected_tasks = [\n        \"Requirements Analysis\",\n        \"Design and Architecture\",\n        \"Implementation\",\n        \"Testing and Documentation\",\n    ]\n\n    for task in expected_tasks:\n        if task not in body:\n            errors.append(f\"Task name '{task}' not found in Epic Tasks section\")\n\n    if errors:\n        return False, errors\n\n    return True, []\n\n\ndef _verify_bug_issue(\n    headers: Dict[str, str], owner: str, repo: str\n) -> Tuple[bool, List[str]]:\n    \"\"\"Verify the bug issue requirements.\"\"\"\n    print(\"\\nüêõ Verifying Bug Issue...\")\n    errors = []\n\n    # Find bug issue\n    bug_issue = _find_issue_by_title(\n        \"Bug: Login form validation not working\", headers, owner, repo\n    )\n    if not bug_issue:\n        return False, [\"Bug issue 'Bug: Login form validation not working' not found\"]\n\n    issue_number = bug_issue[\"number\"]\n    print(f\"   Found bug issue #{issue_number}\")\n\n    # Check labels (including first-time-contributor since it's the first issue)\n    expected_labels = [\"bug\", \"priority-high\", \"needs-review\", \"first-time-contributor\"]\n    labels_ok, label_errors = _check_issue_labels(bug_issue, expected_labels)\n    if not labels_ok:\n        errors.extend(label_errors)\n    else:\n        print(f\"   ‚úÖ Labels verified: {expected_labels}\")\n\n    # Check milestone\n    milestone_ok, milestone_errors = _check_issue_milestone(bug_issue, \"v1.0.0\")\n    if not milestone_ok:\n        errors.extend(milestone_errors)\n    else:\n        print(\"   ‚úÖ Milestone verified: v1.0.0\")\n\n    # Check comment\n    comment_ok, comment_errors = _check_issue_comments(\n        issue_number, \"Bug Report Guidelines\", headers, owner, repo\n    )\n    if not comment_ok:\n        errors.extend(comment_errors)\n    else:\n        print(\"   ‚úÖ Bug Report Guidelines comment found\")\n\n    return len(errors) == 0, errors\n\n\ndef _verify_epic_issue(\n    headers: Dict[str, str], owner: str, repo: str\n) -> Tuple[bool, List[str]]:\n    \"\"\"Verify the epic issue requirements.\"\"\"\n    print(\"\\nüöÄ Verifying Epic Issue...\")\n    errors = []\n\n    # Find epic issue\n    epic_issue = _find_issue_by_title(\n        \"Epic: Redesign user dashboard interface\", headers, owner, repo\n    )\n    if not epic_issue:\n        return False, [\"Epic issue 'Epic: Redesign user dashboard interface' not found\"]\n\n    issue_number = epic_issue[\"number\"]\n    print(f\"   Found epic issue #{issue_number}\")\n\n    # Check labels\n    expected_labels = [\"epic\", \"priority-high\", \"needs-review\"]\n    labels_ok, label_errors = _check_issue_labels(epic_issue, expected_labels)\n    if not labels_ok:\n        errors.extend(label_errors)\n    else:\n        print(f\"   ‚úÖ Labels verified: {expected_labels}\")\n\n    # Check milestone\n    milestone_ok, milestone_errors = _check_issue_milestone(epic_issue, \"v1.0.0\")\n    if not milestone_ok:\n        errors.extend(milestone_errors)\n    else:\n        print(\"   ‚úÖ Milestone verified: v1.0.0\")\n\n    # Check comment\n    comment_ok, comment_errors = _check_issue_comments(\n        issue_number, \"Feature Request Process\", headers, owner, repo\n    )\n    if not comment_ok:\n        errors.extend(comment_errors)\n    else:\n        print(\"   ‚úÖ Feature Request Process comment found\")\n\n    # Find and verify sub-issues\n    sub_issues, sub_errors = _find_epic_sub_issues(issue_number, headers, owner, repo)\n    if sub_errors:\n        errors.extend(sub_errors)\n    elif len(sub_issues) != 4:\n        errors.append(f\"Expected 4 sub-issues, found {len(sub_issues)}\")\n    else:\n        print(f\"   ‚úÖ Found {len(sub_issues)} sub-issues\")\n\n        # Collect sub-issue numbers for checklist verification\n        subtask_numbers = []\n\n        # Verify each sub-issue has correct labels and link to parent\n        for sub_issue in sub_issues:\n            sub_number = sub_issue[\"number\"]\n            subtask_numbers.append(sub_number)\n\n            # Check labels\n            sub_labels = [label[\"name\"] for label in sub_issue.get(\"labels\", [])]\n            expected_sub_labels = [\"enhancement\", \"needs-review\"]\n\n            missing_sub_labels = [\n                label for label in expected_sub_labels if label not in sub_labels\n            ]\n            if missing_sub_labels:\n                errors.append(\n                    f\"Sub-issue #{sub_number} missing labels: {missing_sub_labels}\"\n                )\n\n            # Verify parent reference in body\n            sub_body = sub_issue.get(\"body\", \"\")\n            if (\n                f\"#{issue_number}\" not in sub_body\n                and f\"Related to #{issue_number}\" not in sub_body\n            ):\n                errors.append(\n                    f\"Sub-issue #{sub_number} doesn't reference parent issue #{issue_number}\"\n                )\n\n        if not errors:\n            print(\n                \"   ‚úÖ All 4 sub-tasks created with correct labels and parent references\"\n            )\n\n        # Check Epic Tasks checklist with correct issue numbers\n        checklist_ok, checklist_errors = _check_epic_checklist(\n            epic_issue, subtask_numbers\n        )\n        if not checklist_ok:\n            errors.extend(checklist_errors)\n        else:\n            print(\n                f\"   ‚úÖ Epic Tasks checklist verified with correct issue references: {subtask_numbers}\"\n            )\n\n    return len(errors) == 0, errors\n\n\ndef _verify_maintenance_issue(\n    headers: Dict[str, str], owner: str, repo: str\n) -> Tuple[bool, List[str]]:\n    \"\"\"Verify the maintenance issue requirements.\"\"\"\n    print(\"\\nüîß Verifying Maintenance Issue...\")\n    errors = []\n\n    # Find maintenance issue\n    maintenance_issue = _find_issue_by_title(\n        \"Weekly maintenance cleanup and refactor\", headers, owner, repo\n    )\n    if not maintenance_issue:\n        return False, [\n            \"Maintenance issue 'Weekly maintenance cleanup and refactor' not found\"\n        ]\n\n    issue_number = maintenance_issue[\"number\"]\n    print(f\"   Found maintenance issue #{issue_number}\")\n\n    # Check labels\n    expected_labels = [\"maintenance\", \"priority-medium\", \"needs-review\"]\n    labels_ok, label_errors = _check_issue_labels(maintenance_issue, expected_labels)\n    if not labels_ok:\n        errors.extend(label_errors)\n    else:\n        print(f\"   ‚úÖ Labels verified: {expected_labels}\")\n\n    # Check NO milestone (maintenance issues shouldn't get v1.0.0)\n    milestone_ok, milestone_errors = _check_issue_milestone(maintenance_issue, None)\n    if not milestone_ok:\n        errors.extend(milestone_errors)\n    else:\n        print(\"   ‚úÖ No milestone assigned (correct for maintenance issue)\")\n\n    # Check comment\n    comment_ok, comment_errors = _check_issue_comments(\n        issue_number, \"Maintenance Guidelines\", headers, owner, repo\n    )\n    if not comment_ok:\n        errors.extend(comment_errors)\n    else:\n        print(\"   ‚úÖ Maintenance Guidelines comment found\")\n\n    return len(errors) == 0, errors\n\n\ndef verify() -> bool:\n    \"\"\"\n    Verify that the issue management workflow automation is working correctly.\n    \"\"\"\n    # Load environment variables\n    load_dotenv(\".mcp_env\")\n\n    github_token = os.environ.get(\"MCP_GITHUB_TOKEN\")\n    if not github_token:\n        print(\"Error: MCP_GITHUB_TOKEN environment variable not set\", file=sys.stderr)\n        return False\n\n    # Get GitHub organization\n    github_org = os.environ.get(\"GITHUB_EVAL_ORG\")\n    if not github_org:\n        print(\"Error: GITHUB_EVAL_ORG environment variable not set\", file=sys.stderr)\n        return False\n\n    # Repository configuration\n    owner = github_org\n    repo = \"mcpmark-cicd\"\n\n    headers = {\n        \"Authorization\": f\"token {github_token}\",\n        \"Accept\": \"application/vnd.github.v3+json\",\n    }\n\n    print(\"üîç Starting Issue Management Workflow Verification\")\n    print(\"=\" * 60)\n\n    # Wait for workflows to complete\n    workflows_completed = _wait_for_workflow_completion(headers, owner, repo)\n    if not workflows_completed:\n        print(\n            \"‚ö†Ô∏è Warning: Workflows may still be running. Continuing with verification...\"\n        )\n\n    # Verify each test issue\n    all_passed = True\n\n    # 1. Verify bug issue\n    bug_ok, bug_errors = _verify_bug_issue(headers, owner, repo)\n    if not bug_ok:\n        all_passed = False\n        print(\"‚ùå Bug Issue Verification Failed:\")\n        for error in bug_errors:\n            print(f\"   - {error}\")\n    else:\n        print(\"‚úÖ Bug Issue Verification Passed\")\n\n    # 2. Verify epic issue\n    epic_ok, epic_errors = _verify_epic_issue(headers, owner, repo)\n    if not epic_ok:\n        all_passed = False\n        print(\"‚ùå Epic Issue Verification Failed:\")\n        for error in epic_errors:\n            print(f\"   - {error}\")\n    else:\n        print(\"‚úÖ Epic Issue Verification Passed\")\n\n    # 3. Verify maintenance issue\n    maintenance_ok, maintenance_errors = _verify_maintenance_issue(headers, owner, repo)\n    if not maintenance_ok:\n        all_passed = False\n        print(\"‚ùå Maintenance Issue Verification Failed:\")\n        for error in maintenance_errors:\n            print(f\"   - {error}\")\n    else:\n        print(\"‚úÖ Maintenance Issue Verification Passed\")\n\n    print(\"\\n\" + \"=\" * 60)\n    if all_passed:\n        print(\"üéâ All Issue Management Workflow verifications PASSED!\")\n        print(\"\\nüìã Summary:\")\n        print(\n            \"   ‚úÖ Bug issue: labels (including first-time-contributor), milestone, and auto-response verified\"\n        )\n        print(\n            \"   ‚úÖ Epic issue: labels, milestone, 4 sub-issues with checklist, and correct issue references verified\"\n        )\n        print(\n            \"   ‚úÖ Maintenance issue: labels, no milestone, and auto-response verified\"\n        )\n        print(\"\\nü§ñ The GitHub Actions workflow automation is working correctly!\")\n    else:\n        print(\"‚ùå Issue Management Workflow verification FAILED!\")\n        print(\"   Some issues did not meet the expected automation requirements.\")\n\n    return all_passed\n\n\nif __name__ == \"__main__\":\n    success = verify()\n    sys.exit(0 if success else 1)\n"
}