{
  "task_name": "web_search/r1_arxiv",
  "service": "playwright",
  "model": "deepseek-chat",
  "runs": {
    "run-1": {
      "success": false,
      "error_message": null,
      "tokens": 918877,
      "time": 0,
      "turns": 13
    },
    "run-2": {
      "success": false,
      "error_message": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 131072 tokens. However, you requested 131332 tokens (131332 in the messages, 0 in the completion). Please reduce the length of the messages or completion. (tid: 2025082019112572422856978921714)\", 'type': 'invalid_request_error', 'param': '', 'code': 'invalid_request_error'}}",
      "tokens": 318893,
      "time": 0,
      "turns": 10
    },
    "run-3": {
      "success": false,
      "error_message": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 131072 tokens. However, you requested 139721 tokens (139721 in the messages, 0 in the completion). Please reduce the length of the messages or completion. (tid: 2025082020303549404998274156708)\", 'type': 'invalid_request_error', 'param': '', 'code': 'invalid_request_error'}}",
      "tokens": 864375,
      "time": 0,
      "turns": 15
    },
    "run-4": {
      "success": false,
      "error_message": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 131072 tokens. However, you requested 140218 tokens (140218 in the messages, 0 in the completion). Please reduce the length of the messages or completion. (tid: 2025082021510131107085421138784)\", 'type': 'invalid_request_error', 'param': '', 'code': 'invalid_request_error'}}",
      "tokens": 780790,
      "time": 0,
      "turns": 13
    }
  }
}