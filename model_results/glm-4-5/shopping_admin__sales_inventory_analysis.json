{
  "model": "glm-4-5",
  "service": "playwright",
  "task": "shopping_admin__sales_inventory_analysis",
  "runs": {
    "run-1": {
      "success": false,
      "error_message": "Error code: 400 - {'error': {'message': 'This endpoint\\'s maximum context length is 131072 tokens. However, you requested about 143988 tokens (141430 of text input, 2558 of tool input). Please reduce the length of either one, or use the \"middle-out\" transform to compress your prompt automatically.', 'code': 400, 'metadata': {'provider_name': None}}}",
      "execution_time": 40.864630460739136,
      "token_usage": {
        "input_tokens": 45211,
        "output_tokens": 757,
        "total_tokens": 45968,
        "reasoning_tokens": null
      },
      "turn_count": 6
    },
    "run-2": {
      "success": false,
      "error_message": "Error code: 400 - {'error': {'message': 'This endpoint\\'s maximum context length is 131072 tokens. However, you requested about 156802 tokens (154244 of text input, 2558 of tool input). Please reduce the length of either one, or use the \"middle-out\" transform to compress your prompt automatically.', 'code': 400, 'metadata': {'provider_name': None}}}",
      "execution_time": 47.75757384300232,
      "token_usage": {
        "input_tokens": 91158,
        "output_tokens": 858,
        "total_tokens": 92016,
        "reasoning_tokens": null
      },
      "turn_count": 8
    },
    "run-3": {
      "success": false,
      "error_message": "Error code: 400 - {'error': {'message': 'This endpoint\\'s maximum context length is 131072 tokens. However, you requested about 156914 tokens (154356 of text input, 2558 of tool input). Please reduce the length of either one, or use the \"middle-out\" transform to compress your prompt automatically.', 'code': 400, 'metadata': {'provider_name': None}}}",
      "execution_time": 54.472644567489624,
      "token_usage": {
        "input_tokens": 91326,
        "output_tokens": 879,
        "total_tokens": 92205,
        "reasoning_tokens": null
      },
      "turn_count": 8
    },
    "run-4": {
      "success": false,
      "error_message": "Error code: 400 - {'error': {'message': 'This endpoint\\'s maximum context length is 131072 tokens. However, you requested about 157035 tokens (154477 of text input, 2558 of tool input). Please reduce the length of either one, or use the \"middle-out\" transform to compress your prompt automatically.', 'code': 400, 'metadata': {'provider_name': None}}}",
      "execution_time": 56.95346236228943,
      "token_usage": {
        "input_tokens": 91211,
        "output_tokens": 933,
        "total_tokens": 92144,
        "reasoning_tokens": null
      },
      "turn_count": 8
    }
  }
}