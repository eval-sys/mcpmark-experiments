{
  "model": "glm-4-6",
  "service": "github",
  "task": "mcpmark-cicd__issue_management_workflow",
  "runs": {
    "run-1": {
      "success": false,
      "error_message": null,
      "execution_time": 840.6754078865051,
      "token_usage": {
        "input_tokens": 2258512,
        "output_tokens": 16513,
        "total_tokens": 2275025,
        "reasoning_tokens": 0
      },
      "turn_count": 61
    },
    "run-2": {
      "success": false,
      "error_message": null,
      "execution_time": 359.1804759502411,
      "token_usage": {
        "input_tokens": 1088007,
        "output_tokens": 9824,
        "total_tokens": 1097831,
        "reasoning_tokens": 0
      },
      "turn_count": 37
    },
    "run-3": {
      "success": false,
      "error_message": null,
      "execution_time": 506.37666034698486,
      "token_usage": {
        "input_tokens": 2684040,
        "output_tokens": 12887,
        "total_tokens": 2696927,
        "reasoning_tokens": 0
      },
      "turn_count": 52
    },
    "run-4": {
      "success": false,
      "error_message": "litellm.BadRequestError: OpenrouterException - {\"error\":{\"message\":\"This endpoint's maximum context length is 204800 tokens. However, you requested about 219096 tokens (211019 of text input, 8077 of tool input). Please reduce the length of either one, or use the \\\"middle-out\\\" transform to compress your prompt automatically.\",\"code\":400,\"metadata\":{\"provider_name\":null}}}",
      "execution_time": 589.6776521205902,
      "token_usage": {
        "input_tokens": 3772829,
        "output_tokens": 8350,
        "total_tokens": 3781179,
        "reasoning_tokens": 0
      },
      "turn_count": 62
    }
  }
}