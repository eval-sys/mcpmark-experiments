{
  "model": "deepseek-chat",
  "service": "playwright",
  "task": "shopping_admin__sales_inventory_analysis",
  "runs": {
    "run-1": {
      "success": false,
      "error_message": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 131072 tokens. However, you requested 192026 tokens (192026 in the messages, 0 in the completion). Please reduce the length of the messages or completion. (tid: 2025082102313024121288287807339)\", 'type': 'invalid_request_error', 'param': '', 'code': 'invalid_request_error'}}",
      "execution_time": 137.70611763000488,
      "token_usage": {
        "input_tokens": 167007,
        "output_tokens": 854,
        "total_tokens": 167861,
        "reasoning_tokens": null
      },
      "turn_count": 11
    },
    "run-2": {
      "success": false,
      "error_message": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 131072 tokens. However, you requested 169653 tokens (169653 in the messages, 0 in the completion). Please reduce the length of the messages or completion. (tid: 2025082103402539090859764105171)\", 'type': 'invalid_request_error', 'param': '', 'code': 'invalid_request_error'}}",
      "execution_time": 93.72473692893982,
      "token_usage": {
        "input_tokens": 72135,
        "output_tokens": 599,
        "total_tokens": 72734,
        "reasoning_tokens": null
      },
      "turn_count": 8
    },
    "run-3": {
      "success": false,
      "error_message": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 131072 tokens. However, you requested 200081 tokens (200081 in the messages, 0 in the completion). Please reduce the length of the messages or completion. (tid: 2025082106232467454473723516128)\", 'type': 'invalid_request_error', 'param': '', 'code': 'invalid_request_error'}}",
      "execution_time": 217.31647062301636,
      "token_usage": {
        "input_tokens": 207501,
        "output_tokens": 2248,
        "total_tokens": 209749,
        "reasoning_tokens": null
      },
      "turn_count": 12
    },
    "run-4": {
      "success": false,
      "error_message": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 131072 tokens. However, you requested 192532 tokens (192532 in the messages, 0 in the completion). Please reduce the length of the messages or completion. (tid: 2025082109011449906237865095710)\", 'type': 'invalid_request_error', 'param': '', 'code': 'invalid_request_error'}}",
      "execution_time": 183.90047001838684,
      "token_usage": {
        "input_tokens": 154708,
        "output_tokens": 1083,
        "total_tokens": 155791,
        "reasoning_tokens": null
      },
      "turn_count": 12
    }
  }
}