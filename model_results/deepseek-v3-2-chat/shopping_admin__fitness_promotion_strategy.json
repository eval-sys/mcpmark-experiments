{
  "model": "deepseek-v3-2-chat",
  "service": "playwright",
  "task": "shopping_admin__fitness_promotion_strategy",
  "runs": {
    "run-1": {
      "success": false,
      "error_message": "litellm.BadRequestError: DeepseekException - {\"error\":{\"message\":\"Requested token count exceeds the model's maximum context length of 163840 tokens. You requested a total of 165750 tokens: 157558 tokens from the input messages and 8192 tokens for the completion. Please reduce the number of tokens in the input messages or the completion to fit within the limit. (tid: 2025120122285070027715739017017)\",\"type\":\"upstream_error\",\"param\":\"400\",\"code\":\"bad_response_status_code\"}}\nNoneType: None\n",
      "execution_time": 759.3260905742645,
      "token_usage": {
        "input_tokens": 2078619,
        "output_tokens": 4193,
        "total_tokens": 2082812,
        "reasoning_tokens": 0
      },
      "turn_count": 33
    },
    "run-2": {
      "success": false,
      "error_message": "litellm.ContextWindowExceededError: litellm.BadRequestError: ContextWindowExceededError: DeepseekException - {\"error\":{\"message\":\"This model's maximum context length is 131072 tokens. However, you requested 144277 tokens (144277 in the messages, 0 in the completion). Please reduce the length of the messages or completion. (tid: 2025120203494182483009139121369)\",\"type\":\"invalid_request_error\",\"param\":\"\",\"code\":\"invalid_request_error\"}}\nNoneType: None\n",
      "execution_time": 500.70233249664307,
      "token_usage": {
        "input_tokens": 817751,
        "output_tokens": 2262,
        "total_tokens": 820013,
        "reasoning_tokens": 0
      },
      "turn_count": 15
    },
    "run-3": {
      "success": false,
      "error_message": "litellm.BadRequestError: DeepseekException - {\"error\":{\"message\":\"Model not support (tid: 2025120208360887426605340695220)\",\"type\":\"upstream_error\",\"param\":\"400\",\"code\":\"bad_response_status_code\"}}\nNoneType: None\n",
      "execution_time": 120.23147416114807,
      "token_usage": {
        "input_tokens": 101546,
        "output_tokens": 1441,
        "total_tokens": 102987,
        "reasoning_tokens": 0
      },
      "turn_count": 9
    },
    "run-4": {
      "success": false,
      "error_message": "litellm.ContextWindowExceededError: litellm.BadRequestError: ContextWindowExceededError: DeepseekException - {\"error\":{\"message\":\"This model's maximum context length is 131072 tokens. However, you requested 136139 tokens (136139 in the messages, 0 in the completion). Please reduce the length of the messages or completion. (tid: 202512021302497257045088622586)\",\"type\":\"invalid_request_error\",\"param\":\"\",\"code\":\"invalid_request_error\"}}\nNoneType: None\n",
      "execution_time": 133.63672924041748,
      "token_usage": {
        "input_tokens": 109219,
        "output_tokens": 1833,
        "total_tokens": 111052,
        "reasoning_tokens": 0
      },
      "turn_count": 10
    }
  }
}